question_id,question,user_input,retrieved_contexts,response,reference,faithfulness,answer_relevancy,context_precision,context_recall
1,Apache Airflow là gì và mục đích sử dụng chính của nó là gì?,Apache Airflow là gì và mục đích sử dụng chính của nó là gì?,"['Giới  thiệu  tổng  quan  về  Airflow  \nApache  Airflow  là  một  công  cụ  nguồn  mở  để  tạo,  lên  lịch  và  giám  sát  quy  trình  công  việc  theo  chương  \ntrình.\n \nNó\n \nđược\n \ncác\n \nKỹ\n \nsư\n \nDữ\n \nliệu\n \nsử\n \ndụng\n \nđể\n \nđiều\n \nphối\n \nquy\n \ntrình\n \ncông\n \nviệc\n \nhoặc\n \nđường\n \nống.\n \nNgười\n \ndùng\n \ncó\n \nthể\n \ndễ\n \ndàng\n \nhình\n \ndung\n \ncác\n \nphụ\n \nthuộc,\n \ntiến\n \ntrình,\n \nnhật\n \nký,\n \nmã,\n \ntác\n \nvụ\n \nkích\n \nhoạt\n \nvà\n \ntrạng\n \nthái\n \nthành\n \ncông\n \ncủa\n \nđường\n \nống\n \ndữ\n \nliệu.\n \nNó\n \nquản\n \nlý\n \ncác\n \nđường\n \nống\n \ndữ\n \nliệu\n \nphức\n \ntạp.\n \nCác\n \nđường\n \nống\n \ndữ\n \nliệu\n \nnày\n \nđược\n \nsử\n \ndụng\n \nđể\n \ncung\n \ncấp\n \ncác\n \ntập\n \ndữ\n \nliệu\n \ndễ\n \ndàng\n \nsử\n \ndụng\n \nbởi\n \ncác\n \nứng\n \ndụng\n \ntrí\n \ntuệ\n \nkinh\n \ndoanh\n \nhoặc\n \ncác\n \nmô\n \nhình\n \nhọc\n \nmáy\n \ncần\n \nmột\n \nlượng\n \ndữ\n \nliệu\n \nkhổng\n \nlồ.\n \nĐây\n \nlà\n \nmột\n \ntrong\n \nnhững\n \nnền\n \ntảng\n \nmạnh\n \nmẽ\n \nnhất\n \ndành\n \ncho\n \ncác\n \nkỹ\n \nsư\n \ndữ\n \nliệu.\n 1.  Khởi  nguồn  &  các  giai  đoạn  đầu', 'việc\n \nđiều\n \nphối\n \nvà\n \nđồng\n \nbộ\n \ndữ\n \nliệu\n \ngần\n \nnhư\n \nbất\n \nkhả\n \nthi\n \nnếu\n \nchỉ\n \ndựa\n \nvào\n \ncác\n \ncông\n \ncụ\n \nđơn\n \ngiản.\n \nTất\n \ncả\n \nnhững\n \nkhó\n \nkhăn\n \nnày\n \ntạo\n \nnên\n \nnhu\n \ncầu\n \nbức\n \nthiết\n \nvề\n \nmột\n \nnền\n \ntảng\n \norchestration\n \nthống\n \nnhất\n \n–\n \ncó\n \nkhả\n \nnăng\n \nmô\n \ntả\n \npipeline\n \ndưới\n \ndạng\n \nmã\n \n(workflows\n \nas\n \ncode),\n \nthực\n \nthi\n \nsong\n \nsong,\n \ngiám\n \nsát\n \ntrực\n \nquan,\n \nvà\n \ntự\n \nđộng\n \nhóa\n \ntoàn\n \nbộ\n \nquy\n \ntrình\n \nxử\n \nlý\n \ndữ\n \nliệu\n \nphức\n \ntạp.\n \nĐây\n \ncũng\n \nchính\n \nlà\n \nđộng\n \nlực\n \nđể\n \nApache\n \nAirflow\n \nra\n \nđời.\n \n2.  Lợi  ích  của  Airflow  trong  phân  tích  dữ  liệu  lớn  (Big  Data  Analysis)  \nApache  Airflow  mang  lại  một  bước  tiến  lớn  trong  cách  quản  lý,  lập  lịch  và  vận  hành  các  pipeline  \ndữ\n \nliệu\n \nlớn.\n \nThay\n \nvì\n \nvận\n \nhành\n \nthủ\n \ncông\n \nhoặc\n \nrời\n \nrạc,\n \nAirflow\n \ncho\n \nphép\n \ncác\n \ntổ\n \nchức\n \nđịnh\n \nnghĩa\n \ntoàn\n \nbộ\n \nquy\n \ntrình\n \nxử\n \nlý\n \ndữ\n \nliệu\n \nnhư\n \nmột\n \nđồ\n \nthị\n \ncó\n \nhướng\n \n(DAG', 'nền\n \ntảng\n \nmạnh\n \nmẽ\n \nnhất\n \ndành\n \ncho\n \ncác\n \nkỹ\n \nsư\n \ndữ\n \nliệu.\n 1.  Khởi  nguồn  &  các  giai  đoạn  đầu  \nApache  Airflow  ra  đời  vào  năm  2014  tại  Airbnb ,  do  Maxime  Beauchemin  khởi  xướng  nhằm  giải  \nquyết\n \nvấn\n \nđề\n \nquản\n \nlý\n \nvà\n \ntự\n \nđộng\n \nhóa\n \ncác\n \nluồng\n \ncông\n \nviệc\n \n(workflow)\n \nphân\n \ntích\n \ndữ\n \nliệu\n \nphức\n \ntạp\n \ntrong\n \nhệ\n \nthống\n \nphân\n \ntán\n \ncủa\n \ncông\n \nty.\n \nĐến\n \nnăm\n \n2015\n,\n \nAirflow\n \nđược\n \nchính\n \nthức\n \nphát\n \nhành\n \ndưới\n \ndạng\n \nmã\n \nnguồn\n \nmở\n,\n \nnhanh\n \nchóng\n \nthu\n \nhút\n \nsự\n \nquan\n \ntâm\n \ncủa\n \ncộng\n \nđồng\n \nkỹ\n \nsư\n \ndữ\n \nliệu.\n \nTháng\n \n3\n \nnăm\n \n2016,\n \ndự\n \nán\n \nđược\n \nApache\n \nSoftware\n \nFoundation\n \nchấp\n \nnhận\n \nvào\n \nchương\n \ntrình\n \nIncubator\n,\n \nđánh\n \ndấu\n \nbước\n \nngoặt\n \nlớn\n \nvề\n \ntính\n \nminh\n \nbạch,\n \nđộ\n \ntin\n \ncậy\n \nvà\n \nquy\n \nmô\n \ncộng\n \nđồng\n \nđóng\n \ngóp.\n \nĐến\n \nđầu\n \nnăm\n \n2019\n,\n \nAirflow\n \nđã\n \ntrưởng\n \nthành\n \nđủ\n \nđể\n \ntrở\n \nthành\n \nTop-Level\n \nProject\n \ncủa\n \nApache\n,\n \nthể\n \nhiện\n \nvị\n \nthế', 'Executor\n \nphân\n \ntán\n \n(như\n \nCeleryExecutor\n \nhoặc\n \nKubernetesExecutor),\n \ncho\n \nphép\n \nchạy\n \nhàng\n \nnghìn\n \ntác\n \nvụ\n \nsong\n \nsong\n \ntrên\n \nnhiều\n \nmáy\n \nchủ,\n \ngiúp\n \nđáp\n \nứng\n \nkhối\n \nlượng\n \ndữ\n \nliệu\n \nkhổng\n \nlồ\n \ntrong\n \ncác\n \ndự\n \nán\n \nBig\n \nData.\n \nNgoài\n \nra,\n \nvới\n \ngiao\n \ndiện\n \nweb\n \ntrực\n \nquan\n,\n \nngười\n \ndùng\n \ncó\n \nthể\n \ndễ\n \ndàng\n \ngiám\n \nsát\n \npipeline,\n \nkiểm\n \ntra\n \nlog,\n \nthực\n \nhiện\n \nretry\n \nhoặc\n \nbackfill,\n \nvà\n \nphát\n \nhiện\n \nlỗi\n \nsớm.\n \nAirflow\n \ncũng\n \nđược\n \nthiết\n \nkế\n \nđể\n \ntích\n \nhợp\n \nsâu\n \nvới\n \ntoàn\n \nbộ\n \nhệ\n \nsinh\n \nthái\n \nBig\n \nData\n \nhiện\n \nđại\n,\n \ntừ\n \ncác\n \ncông\n \ncụ\n \nxử\n \nlý\n \nnhư\n \nApache\n \nSpark,\n \nHadoop,\n \nKafka\n \ncho\n \nđến\n \ncác\n \ndịch\n \nvụ\n \nlưu\n \ntrữ\n \nvà\n \nwarehouse\n \nnhư\n \nAmazon\n \nS3,\n \nGoogle\n \nBigQuery,\n \nSnowflake\n.\n \nNhờ\n \nđó,\n \nAirflow\n \nkhông\n \nchỉ\n \nđơn\n \nthuần\n \nlà\n \nmột\n \ntrình\n \nlập\n \nlịch\n \ncông\n \nviệc,\n \nmà\n \ntrở\n \nthành\n \n“bộ\n \nnão\n \nđiều\n \nphối”\n \ncủa\n \nhệ\n \nthống\n \ndữ\n \nliệu\n \nlớn\n \n—\n \nđảm\n \nbảo\n \nmọi\n \nquy', 'Airflow\n \nđã\n \ntrưởng\n \nthành\n \nđủ\n \nđể\n \ntrở\n \nthành\n \nTop-Level\n \nProject\n \ncủa\n \nApache\n,\n \nthể\n \nhiện\n \nvị\n \nthế\n \ncủa\n \nnó\n \nnhư\n \nmột\n \ncông\n \ncụ\n \nđiều\n \nphối\n \ndữ\n \nliệu\n \ntiêu\n \nchuẩn\n \ntrong\n \nhệ\n \nsinh\n \nthái\n \nBig\n \nData.\n \n2.  Bước  chuyển  lớn:  Airflow  2.0  \nNgày  17  tháng  12  năm  2020 ,  Airflow  2.0.0  chính  thức  ra  mắt  —  được  xem  là  phiên  bản  đột  \nphá\n \nnhất\n \nkể\n \ntừ\n \nkhi\n \ndự\n \nán\n \nra\n \nđời.\n \nPhiên\n \nbản\n \nnày\n \ngiới\n \nthiệu\n \nTaskFlow\n \nAPI\n,\n \ncho\n \nphép\n \nđịnh\n \nnghĩa\n \nDAGs\n \nbằng\n \ndecorator\n \nPython\n \n(@task),\n \ngiúp\n \ncode\n \ntrực\n \nquan,\n \ndễ\n \nkiểm\n \nthử\n \nvà\n \ndễ\n \nbảo\n \ntrì\n \nhơn.\n \nNgoài\n \nra,\n \nAirflow\n \n2.0\n \nmang\n \nđến\n \nREST\n \nAPI\n \nhoàn\n \nchỉnh\n \n(AIP-32)\n \ngiúp\n \ntự\n \nđộng\n \nhóa\n \nvà\n \ntích\n \nhợp\n \ndễ\n \ndàng\n \nhơn\n \ntrong\n \nmôi\n \ntrường\n \ndoanh\n \nnghiệp.\n \nScheduler\n \nđược\n \nthiết\n \nkế\n \nlại\n \nhoàn\n \ntoàn,\n \nhỗ\n \ntrợ\n \nđa\n \nluồng\n,\n \nphân\n \ntán\n \ncao\n,\n \nvà\n \nxử\n \nlý\n \nsong\n \nsong\n \nhiệu\n \nquả\n \nhơn\n,\n \nđưa\n \nAirflow\n \ntrở\n \nthành', 'công\n \nviệc\n \ncần\n \nthực\n \nhiện\n.\n \nNói\n \ncách\n \nkhác,\n \nmột\n \nOperator\n \nchính\n \nlà\n \n“class”\n \ncòn\n \nTask\n \nlà\n \n“instance”\n \nđược\n \nsử\n \ndụng\n \ntrong\n \nDAG.\n \nAirflow  cung  cấp  nhiều  loại  Operator  khác  nhau,  được  chia  theo  mục  đích  sử  dụng:  \nNhóm  Ví  dụ  Chức  năng  \nCore  Operators  \nPythonOperator,  BashOperator,  EmailOperator \nThực  thi  script  Python,  command  shell,  gửi  email,  v.v.  \nTransfer  Operators  \nS3ToRedshiftOperator,  MySqlToGCSOperator \nDi  chuyển  dữ  liệu  giữa  các  nó  hệ  thống.  \nAction  Operators  \nSparkSubmitOperator,  DockerOperator,  KubernetesPodOperator \nChạy  job  xử  lý  dữ  liệu  hoặc  container  trên  các  nền  tảng  khác  nhau.  \nSensor  Operators  \nFileSensor,  ExternalTaskSensor \nChờ  đợi  một  điều  kiện  xảy  ra  (ví  dụ:  file  xuất  hiện,  task  khác  hoàn  tất).', 'nút,\n \nmiễn\n \nlà\n \nluôn\n \ntuân\n \ntheo\n \nhướng\n \ncủa\n \ncác\n \ncạnh.\n \n“Acyclic”\n \nnghĩa\n \nlà\n \nkhông\n \ntồn\n \ntại\n \nvòng\n \nlặp\n \n—\n \nmột\n \ntask\n \nkhông\n \nthể\n \nphụ\n \nthuộc\n \nngược\n \nlại\n \nchính\n \nnó.\n \nĐiều\n \nnày\n \nđảm\n \nbảo\n \nrằng\n \nmỗi\n \nworkflow\n \ncó\n \nđiểm\n \nbắt\n \nđầu\n \nvà\n \nkết\n \nthúc\n \nxác\n \nđịnh,\n \ntránh\n \ncác\n \nvòng\n \nlặp\n \nvô\n \nhạn\n \ntrong\n \nxử\n \nlý.\n \nVề\n \nbản\n \nchất,\n \nDAG\n \ntrong\n \nAirflow\n \nlà\n \nmột\n \nđồ\n \nthị\n \ncó\n \nhướng\n \nvà\n \nkhông\n \nchu\n \ntrình\n,\n \nđược\n \nđịnh\n \nnghĩa\n \nbằng\n \nmã\n \nPython\n,\n \ncho\n \nphép\n \nngười\n \ndùng\n \nbiểu\n \ndiễn\n \nvà\n \nđiều\n \nkhiển\n \nluồng\n \nxử\n \nlý\n \ndữ\n \nliệu\n \nmột\n \ncách\n \nlinh\n \nhoạt,\n \ncó\n \nthể\n \nkiểm\n \nthử,\n \nvà\n \ndễ\n \ndàng\n \nquản\n \nlý\n \nphiên\n \nbản\n \n(version\n \ncontrol).\n \nVai  trò  trung  tâm  của  DAG  trong  Airflow  \nDAG  được  xem  là  trung  tâm  của  kiến  trúc  Airflow  vì  nó  chính  là  “ngôn  ngữ  chung”  để  mô  tả,  lập  lịch,  \nvà\n \nđiều\n \nphối\n \ncác\n \nluồng\n \ncông\n \nviệc.\n \nThay\n \nvì\n \nphải\n \nchạy\n \nthủ\n \ncông\n \ncác\n \nscript', 'Custom  Operators  \nNgười  dùng  tự  định  nghĩa  subclass  Operator  riêng  \nDùng  cho  logic  nghiệp  vụ  cụ  thể  hoặc  tích  hợp  hệ  thống  nội  bộ.  \nVí  dụ,  một  task  dùng  PythonOperator  có  thể  được  định  nghĩa  như  sau:  \nfrom  airflow.operators.python  import  PythonOperator  \ndef  transform_data():  \nprint(""Transforming  data..."")  \ntransform_task  =  PythonOperator(  \ntask_id=\'transform_data\',  \n     python_callable=transform_data)  \n \nỞ  đây,  transform_task là  Task  Instance  của  Operator  PythonOperator.  Mỗi  Task  có  các  thuộc  \ntính\n \nquan\n \ntrọng\n \nnhư:\n \n●  task_id:  định  danh  duy  nhất  trong  DAG.  ●  python_callable (hoặc  bash_command…):  hành  động  cần  thực  thi.  ●  retries,  retry_delay:  cấu  hình  retry  khi  task  lỗi.  ●  depends_on_past:  quy  định  task  có  cần  chờ  phiên  bản  trước  của  chính  nó  hoàn  tất  không.', 'Ưu  điểm  của  LocalExecutor  \nƯu  điểm  lớn  nhất  là  đơn  giản  và  dễ  triển  khai .  Người  dùng  không  cần  cài  đặt  message  broker,  không  \ncần\n \nworker\n \ncluster,\n \nmà\n \nvẫn\n \ncó\n \nkhả\n \nnăng\n \nchạy\n \nsong\n \nsong\n \nnhiều\n \ntask\n.\n \nLocalExecutor\n \ncũng\n \ngiúp\n \nđơn\n \ngiản\n \nhóa\n \nviệc\n \ntheo\n \ndõi\n \nlog,\n \nvì\n \ntoàn\n \nbộ\n \nlog\n \nvà\n \ntrạng\n \nthái\n \ntask\n \nđược\n \nlưu\n \ntập\n \ntrung\n \ntrên\n \nmột\n \nmáy.\n \nĐối\n \nvới\n \ncác\n \nnhóm\n \nnhỏ\n \nhoặc\n \nmôi\n \ntrường\n \nthử\n \nnghiệm,\n \nLocalExecutor\n \nmang\n \nlại\n \nsự\n \ncân\n \nbằng\n \ntốt\n \ngiữa\n \nhiệu\n \nnăng\n \nvà\n \nđộ\n \nphức\n \ntạp.\n \nNhược  điểm  của  LocalExecutor  \nNhược  điểm  chính  là  giới  hạn  tài  nguyên  và  khả  năng  mở  rộng .  Toàn  bộ  task  và  Scheduler  cùng  chia  \nsẻ\n \nCPU,\n \nRAM\n \nvà\n \nổ\n \nđĩa\n \ntrên\n \nmột\n \nnode\n \nduy\n \nnhất,\n \nnên\n \nkhi\n \nworkload\n \ntăng\n \ncao,\n \nhệ\n \nthống\n \ndễ\n \nbị\n \nquá\n \ntải.\n \nNgoài\n \nra,\n \nnếu\n \nmáy\n \nchủ\n \ngặp\n \nsự\n \ncố,\n \ntoàn\n \nbộ\n \npipeline\n \nsẽ\n \ndừng\n \nlại\n \n—\n \nkhông\n \ncó\n \nkhả\n \nnăng', '“Chỉ  có  4  process  được  tạo  ra  sẵn,  và  4  process  đó  sẽ  thay  nhau  xử  lý  các  task.”  \nCơ  chế:  \n●  Airflow  tạo  ra  4  process  cố  định  (gọi  là  QueuedLocalWorker ).  ●  Các  process  này  đọc  task  từ  một  hàng  đợi  (task_queue) .  ●  Khi  một  worker  rảnh  (vì  vừa  xong  task),  nó  lấy  task  tiếp  theo  từ  hàng  đợi  để  chạy.  ●  Khi  không  còn  task  →  Scheduler  gửi  “poison  token”  để  worker  biết  là  “đã  hết  việc”,  rồi  tự  dừng  \nan\n \ntoàn\n \nGiả  sử  có  10  task,  và  parallelism  =  4:  \n●  Airflow  khởi  tạo  4  process  chạy  4  task  đầu  tiên.  ●  Khi  1  trong  4  process  hoàn  thành  →  nó  lấy  tiếp  task  thứ  5,  rồi  task  6,  v.v…  ●  Tổng  cộng  vẫn  chỉ  có  4  process  hoạt  động  cùng  lúc  →  không  gây  quá  tải.  \nƯu\n \nđiểm:\n ●  Kiểm  soát  tốt  tài  nguyên  (CPU,  RAM).  ●  Ổn  định  hơn  cho  máy  có  cấu  hình  hạn  chế.']",Apache Airflow là một hệ thống quản lý luồng công việc dựa trên Python. Nó được thiết kế để giúp lập lịch và giám sát các tác vụ trong các quy trình phức tạp của data pipeline hoặc bất kỳ quy trình nào mà bạn có thể tự động hoá. Mục đích chính của Apache Airflow là cho phép các nhà phát triển và người quản lý quy trình điều khiển và chạy các tác vụ dựa trên thời gian thực hiện và các quy tắc tiên đoán được lập trình trước.,"Apache Airflow là một công cụ nguồn mở dùng để tạo, lên lịch và giám sát quy trình công việc (workflow) theo chương trình. Nó được các kỹ sư dữ liệu sử dụng để điều phối các đường ống dữ liệu (data pipelines) phức tạp, giúp quản lý phụ thuộc, tiến trình, và trạng thái của các tác vụ.",,0.9589320080360914,0.9765432098656928,
2,Kiến trúc của Airflow gồm những thành phần chính nào và chức năng của Scheduler là gì?,Kiến trúc của Airflow gồm những thành phần chính nào và chức năng của Scheduler là gì?,"['Kiến  trúc  tổng  quan  \nScheduler  –  Bộ  lập  lịch  trung  tâm  \nScheduler  là  trái  tim  của  hệ  thống  Airflow ,  chịu  trách  nhiệm  phát  hiện,  lập  lịch  và  kích  hoạt  các  tác  \nvụ\n \n(tasks)\n \ntrong\n \ncác\n \nluồng\n \ncông\n \nviệc\n \n(workflows).\n \nKhi\n \nngười\n \ndùng\n \nđịnh\n \nnghĩa\n \nmột\n \nDAG\n \n(Directed\n \nAcyclic\n \nGraph)\n \n—\n \ntức\n \nlà\n \ntập\n \nhợp\n \ncác\n \ntác\n \nvụ\n \nvà\n \nmối\n \nquan\n \nhệ\n \nphụ\n \nthuộc\n \ngiữa\n \nchúng\n \n—\n \nScheduler\n \nsẽ\n \nquét\n \ncác\n \nfile\n \nDAG\n \nđược\n \nlưu\n \ntrong\n \nthư\n \nmục\n \ncấu\n \nhình,\n \nphân\n \ntích\n \nlogic\n \nphụ\n \nthuộc\n \nvà\n \nxác\n \nđịnh\n \nkhi\n \nnào\n \nmột\n \ntask\n \nđủ\n \nđiều\n \nkiện\n \nđể\n \nchạy.\n \nSau\n \nđó,\n \nScheduler\n \nsẽ\n \nđẩy\n \nyêu\n \ncầu\n \nthực\n \nthi\n \n(task\n \ninstance)\n \ntới\n \nExecutor\n \nđể\n \nbắt\n \nđầu\n \nquá\n \ntrình\n \nxử\n \nlý.\n \nScheduler\n \ncũng\n \nlà\n \nnơi\n \nđiều\n \nphối\n \ncác\n \ncơ\n \nchế\n \nnhư\n \nretry\n \n(chạy\n \nlại\n \ntask\n \nnếu\n \nlỗi)\n,\n \nbackfill\n \n(chạy\n \nlại\n \ndữ\n \nliệu\n \nlịch\n \nsử)\n,\n \nvà\n \ncatchup\n \n(chạy\n \nbù\n \ncác\n \nlịch\n \nbị\n \ntrễ)\n.\n \nNhờ', ',\n \nbackfill\n \n(chạy\n \nlại\n \ndữ\n \nliệu\n \nlịch\n \nsử)\n,\n \nvà\n \ncatchup\n \n(chạy\n \nbù\n \ncác\n \nlịch\n \nbị\n \ntrễ)\n.\n \nNhờ\n \ncó\n \nScheduler,\n \nAirflow\n \nđảm\n \nbảo\n \ntoàn\n \nbộ\n \nworkflow\n \nđược\n \nđiều\n \nphối\n \ncó\n \ntrật\n \ntự,\n \nđúng\n \nthời\n \ngian,\n \nvà\n \nkhông\n \nbị\n \nbỏ\n \nsót.\n \nTrong\n \nmôi\n \ntrường\n \nlớn,\n \ncó\n \nthể\n \nchạy\n \nnhiều\n \nScheduler\n \nsong\n \nsong\n \nđể\n \ntăng\n \nkhả\n \nnăng\n \nchịu\n \ntải\n \nvà\n \nđảm\n \nbảo\n \ntính\n \nsẵn\n \nsàng\n \ncao\n \n(High\n \nAvailability).\n \nExecutor  –  Bộ  điều  phối  thực  thi  \nExecutor  là  thành  phần  quyết  định  cách  thức  các  task  được  thực  thi  và  nơi  nào  chúng  sẽ  chạy .  Nó  \nđóng\n \nvai\n \ntrò\n \ntrung\n \ngian\n \ngiữa\n \nScheduler\n \nvà\n \nWorker.\n \nKhi\n \nScheduler\n \nphát\n \nhiện\n \nmột\n \ntask\n \nsẵn\n \nsàng\n \nchạy,\n \nnó\n \nsẽ\n \ngửi\n \nthông\n \ntin\n \ncho\n \nExecutor,\n \nvà\n \nExecutor\n \nsẽ\n \nquyết\n \nđịnh\n \ngửi\n \ntask\n \nđó\n \nđến\n \nWorker\n \nnào\n \nhoặc\n \nchạy\n \ntrực\n \ntiếp\n \n(tùy\n \nloại\n \nExecutor).\n \nAirflow\n \nhỗ\n \ntrợ\n \nnhiều\n \nloại\n \nExecutor\n \nkhác\n \nnhau:', 'Kiến  trúc  phân  tán  (Distributed  Architecture)  \n \nAirflow  được  thiết  kế  theo  mô  hình  phân  tán  (distributed) ,  tách  biệt  giữa  lập  lịch  (Scheduler)  và  thực  \nthi\n \n(Workers)\n.\n \nTrong\n \nmột\n \ntriển\n \nkhai\n \nproduction\n \nđiển\n \nhình,\n \ncác\n \nthành\n \nphần\n \ncó\n \nthể\n \nnằm\n \ntrên\n \ncác\n \nmáy\n \nchủ\n \nriêng\n \nbiệt:\n \n●  Node  A:  Scheduler  ●  Node  B:  Webserver  ●  Node  C:  Metadata  Database  ●  Node  D:  Message  Broker  (Redis/RabbitMQ)  ●  Nhiều  Node  khác:  Workers  (xử  lý  task  song  song)  \nEdge  Worker  trong  Apache  Airflow  là  một  node  worker  “phân  tán”  được  triển  khai  tại  vị  trí  biên  (edge  \nsite)\n,\n \ncho\n \nphép\n \nthực\n \nthi\n \ncác\n \ntác\n \nvụ\n \nngay\n \ngần\n \nnguồn\n \ndữ\n \nliệu\n \nthay\n \nvì\n \ntại\n \ntrung\n \ntâm\n \ndữ\n \nliệu\n \nchính.\n \nNó\n \nkết\n \nnối\n \nvới\n \ncluster\n \ntrung\n \ntâm\n \nqua\n \nHTTP(S)\n \nmà\n \nkhông\n \ncần\n \nmessage\n \nbroker,\n \ngiúp\n \nvượt\n \nqua\n \ncác\n \nrào\n \ncản\n \nmạng\n \nnhư\n \nfirewall\n \nhoặc\n \nNAT.\n \nTrong\n \nkiến\n \ntrúc\n \nphân\n \ntán,', 'Executor  và  Worker  chịu  trách  nhiệm  chạy  chúng.  Bằng  cách  này,  Airflow  có  thể  mở  rộng  quy  mô  linh  \nhoạt,\n \nquản\n \nlý\n \nsong\n \nsong\n \nhàng\n \ntrăm\n \npipeline\n \nkhác\n \nnhau.\n \nNgoài\n \nra,\n \nDAG\n \ncòn\n \ngiúp\n \nhiển\n \nthị\n \ntoàn\n \nbộ\n \ncấu\n \ntrúc\n \nworkflow\n \ntrên\n \ngiao\n \ndiện\n \nWeb\n \nUI,\n \ngiúp\n \nnhóm\n \nkỹ\n \nsư\n \ndữ\n \nliệu\n \ntheo\n \ndõi,\n \nquản\n \nlý,\n \nvà\n \nkhắc\n \nphục\n \nsự\n \ncố\n \ndễ\n \ndàng\n \ntrong\n \nhệ\n \nthống\n \nBig\n \nData\n \nphức\n \ntạp.\n \nMột  DAG  trong  Airflow  gồm  nhiều  thành  phần  cấu  trúc  cốt  lõi.  Đầu  tiên  là  DAG  object ,  được  khai  báo  \ntrong\n \nmã\n \nPython\n \nvới\n \ncác\n \ntham\n \nsố\n \nnhư\n dag_id (định  danh  DAG),  start_date (ngày  bắt  đầu),  schedule (chu  kỳ  chạy),  default_args (các  tham  số  mặc  định  cho  tasks),  và  catchup (xác  định  có  \nchạy\n \nbù\n \nnhững\n \nlần\n \nbị\n \nbỏ\n \nlỡ\n \nhay\n \nkhông).\n \nNgoài\n \nra,\n \nDAG\n \ncòn\n \ncó\n \ncác\n \nthuộc\n \ntính\n \nđiều\n \nkhiển\n \nnhư', 'Scheduler,\n \nthay\n \nvì\n \ngửi\n \nđi\n \ncho\n \ncác\n \nworker\n \ntừ\n \nxa.\n \nLocalExecutor\n \nthường\n \nđược\n \nsử\n \ndụng\n \ntrong\n \nmôi\n \ntrường\n \nphát\n \ntriển\n \n(development)\n \nhoặc\n \nsản\n \nxuất\n \nnhỏ\n \n(small-scale\n \nproduction)\n.\n \nNó\n \nthích\n \nhợp\n \ncho\n \ncác\n \nhệ\n \nthống\n \ncó\n \nlượng\n \ntác\n \nvụ\n \nvừa\n \nphải,\n \ncần\n \nchạy\n \nsong\n \nsong\n \nnhưng\n \nkhông\n \ncần\n \nphân\n \ntán\n \ntrên\n \nnhiều\n \nmáy.\n \nƯu\n \nđiểm\n \nlớn\n \nnhất\n \ncủa\n \nLocalExecutor\n \nlà\n \nthiết\n \nlập\n \ndễ\n \ndàng:\n \nchỉ\n \ncần\n \nthay\n \nđổi\n \ncấu\n \nhình\n executor  =  \nLocalExecutor trong  file  airflow.cfg và  bảo  đảm  sử  dụng  cơ  sở  dữ  liệu  thực  (PostgreSQL  hoặc  \nMySQL).\n \nVì\n \nSQLite\n \nkhông\n \nhỗ\n \ntrợ\n \ntruy\n \ncập\n \nđồng\n \nthời\n \nnhiều\n \nprocess,\n \nnên\n \nkhông\n \nthể\n \ndùng\n \ncho\n \nLocalExecutor.\n  \nScheduler\n \ncủa\n \nAirflow\n \nchịu\n \ntrách\n \nnhiệm\n \nlên\n \nlịch\n \ncác\n \ntask,\n \ncập\n \nnhật\n \ntrạng\n \nthái\n \ncủa\n \nchúng\n \nvào\n \nmetadata\n \ndatabase\n \n.\n \nKhi\n \nmột\n \ntask\n \nđến\n \nlượt\n \nthực\n \nthi,\n \nScheduler\n \ngửi\n \nlệnh', 'nút,\n \nmiễn\n \nlà\n \nluôn\n \ntuân\n \ntheo\n \nhướng\n \ncủa\n \ncác\n \ncạnh.\n \n“Acyclic”\n \nnghĩa\n \nlà\n \nkhông\n \ntồn\n \ntại\n \nvòng\n \nlặp\n \n—\n \nmột\n \ntask\n \nkhông\n \nthể\n \nphụ\n \nthuộc\n \nngược\n \nlại\n \nchính\n \nnó.\n \nĐiều\n \nnày\n \nđảm\n \nbảo\n \nrằng\n \nmỗi\n \nworkflow\n \ncó\n \nđiểm\n \nbắt\n \nđầu\n \nvà\n \nkết\n \nthúc\n \nxác\n \nđịnh,\n \ntránh\n \ncác\n \nvòng\n \nlặp\n \nvô\n \nhạn\n \ntrong\n \nxử\n \nlý.\n \nVề\n \nbản\n \nchất,\n \nDAG\n \ntrong\n \nAirflow\n \nlà\n \nmột\n \nđồ\n \nthị\n \ncó\n \nhướng\n \nvà\n \nkhông\n \nchu\n \ntrình\n,\n \nđược\n \nđịnh\n \nnghĩa\n \nbằng\n \nmã\n \nPython\n,\n \ncho\n \nphép\n \nngười\n \ndùng\n \nbiểu\n \ndiễn\n \nvà\n \nđiều\n \nkhiển\n \nluồng\n \nxử\n \nlý\n \ndữ\n \nliệu\n \nmột\n \ncách\n \nlinh\n \nhoạt,\n \ncó\n \nthể\n \nkiểm\n \nthử,\n \nvà\n \ndễ\n \ndàng\n \nquản\n \nlý\n \nphiên\n \nbản\n \n(version\n \ncontrol).\n \nVai  trò  trung  tâm  của  DAG  trong  Airflow  \nDAG  được  xem  là  trung  tâm  của  kiến  trúc  Airflow  vì  nó  chính  là  “ngôn  ngữ  chung”  để  mô  tả,  lập  lịch,  \nvà\n \nđiều\n \nphối\n \ncác\n \nluồng\n \ncông\n \nviệc.\n \nThay\n \nvì\n \nphải\n \nchạy\n \nthủ\n \ncông\n \ncác\n \nscript', 'Luồng  hoạt  động  (Workflow  Lifecycle)  trong  Airflow  diễn  ra  theo  các  bước  tuần  tự:  \n1.  Kỹ  sư  dữ  liệu  định  nghĩa  DAG  bằng  Python,  bao  gồm  các  task  và  dependencies  giữa  chúng.  2.  Scheduler  quét  DAGs ,  xác  định  những  task  nào  sẵn  sàng  chạy  (theo  lịch  hoặc  phụ  thuộc).  3.  Executor  gửi  các  task  đến  hàng  đợi  thông  điệp  (nếu  dùng  Celery/Kubernetes)  hoặc  trực  tiếp  \nđến\n \nWorker.\n 4.  Worker  nhận  và  thực  thi  task ,  ví  dụ:  gọi  Spark  job,  tải  dữ  liệu  từ  API,  hoặc  ghi  vào  database.  5.  Sau  khi  hoàn  thành,  Worker  ghi  lại  trạng  thái  của  task  vào  Metadata  Database.  6.  Webserver  đọc  dữ  liệu  từ  database  và  hiển  thị  trạng  thái  cập  nhật  trên  Web  UI.  \nToàn  bộ  chu  trình  này  diễn  ra  liên  tục  và  tự  động,  đảm  bảo  hàng  trăm  pipeline  có  thể  được  lập  lịch  và  \ngiám\n \nsát\n \nsong\n \nsong\n \nmà\n \nkhông\n \ncần\n \ncan\n \nthiệp\n \nthủ\n \ncông.', 'Hạn  chế  của  kiến  trúc  Airflow  \nMặc  dù  mạnh  mẽ,  kiến  trúc  Airflow  vẫn  có  một  số  hạn  chế  đáng  chú  ý :  \n●  Không  phù  hợp  cho  xử  lý  real-time  (thời  gian  thực) :  Airflow  được  thiết  kế  cho  batch  \nprocessing\n \n(xử\n \nlý\n \ntheo\n \nlô),\n \nnên\n \nkhông\n \ntối\n \nưu\n \ncho\n \ndữ\n \nliệu\n \nstreaming\n \ncó\n \nđộ\n \ntrễ\n \nthấp\n \nnhư\n \nKafka\n \nhoặc\n \nFlink.\n ●  Độ  phức  tạp  trong  triển  khai :  Khi  hệ  thống  lớn,  việc  quản  lý  nhiều  node  (Scheduler,  Worker,  \nDatabase,\n \nBroker)\n \ntrở\n \nnên\n \nkhó\n \nkhăn;\n \ncần\n \nkỹ\n \nnăng\n \nDevOps\n \ntốt\n \nđể\n \nvận\n \nhành\n \nổn\n \nđịnh.\n ●  Phụ  thuộc  vào  cơ  sở  dữ  liệu  trung  tâm :  Nếu  Metadata  Database  bị  nghẽn  hoặc  lỗi,  toàn  bộ  \nAirflow\n \ncó\n \nthể\n \nbị\n \nảnh\n \nhưởng.\n ●  Không  tối  ưu  cho  workflow  quá  nhỏ  hoặc  thay  đổi  liên  tục ,  vì  việc  parse  và  schedule  DAG  \ntốn\n \nchi\n \nphí\n \nnhất\n \nđịnh.\n \nDAG  (Directed  Acyclic  Graph)  \nKhái  niệm  DAG  trong  Airflow']","Kiến trúc của Airflow bao gồm các thành phần chính sau:

1. Scheduler: Đây là trái tim của hệ thống Airflow chịu trách nhiệm phát hiện, lập lịch và kích hoạt các任务. Nó xác định thời gian chạy cho mỗi task dựa trên schedule đã thiết lập và thông báo cho Executor khi một task có thể được thực thi.

2. Executor: Các task sau khi được Scheduler gửi đến sẽ được Executor xử lý. Thực thi các tác vụ có thể bao gồm việc gọi Spark job, tải dữ liệu từ API hoặc ghi vào database.

3. Worker: Nhận và thực hiện các task từ Executor. Việc thực hiện nhiệm vụ này có thể là gọi một số công việc như Spark Job hoặc tải dữ liệu từ API.

4. Metadata Database: Ghi lại trạng thái của mỗi task sau khi nó được thực thi bởi Worker để Scheduler có thể cập nhật thông tin về tiến trình của mỗi task.

5. Webserver: Đọc dữ liệu từ Metadata Database và hiển thị trạng thái của các task trên UI web, cung cấp một cách dễ dàng để quản lý và giám sát quá trình.

Công việc của Scheduler trong kiến trúc Airflow là xác định thời gian và thứ tự thực thi các tasks dựa trên schedule đã được thiết lập.","Kiến trúc Airflow gồm các thành phần: Scheduler, Executor, Worker, Metadata Database và Web UI. Trong đó, Scheduler là bộ lập lịch trung tâm, chịu trách nhiệm quét các file DAG, phân tích logic phụ thuộc, xác định khi nào một task đủ điều kiện chạy và đẩy yêu cầu thực thi tới Executor.",,0.8876280631480623,0.9999999999875,
3,So sánh sự khác biệt giữa LocalExecutor và CeleryExecutor.,So sánh sự khác biệt giữa LocalExecutor và CeleryExecutor.,"['vốn  đang  lắng  nghe  queue  –  nhận  lệnh,  thực  thi  task  trong  môi  trường  của  mình  và  ghi  kết  quả  vào  \nresult\n \nbackend\n.\n \nKhi\n \ntask\n \nhoàn\n \ntất,\n \ntrạng\n \nthái\n \nđược\n \nđồng\n \nbộ\n \nlại\n \nvề\n \nScheduler\n \nqua\n \nmetadata\n \ndatabase.\n \nNếu\n \nworker\n \ngặp\n \nsự\n \ncố\n \ngiữa\n \nchừng,\n \ntask\n \ncó\n \nthể\n \nđược\n \nđưa\n \nlại\n \nvào\n \nqueue\n \nđể\n \nmột\n \nworker\n \nkhác\n \nxử\n \nlý\n \n(tùy\n \ncấu\n \nhình).\n \nCơ\n \nchế\n \nnày\n \ngiúp\n \nCeleryExecutor\n \nđảm\n \nbảo\n \ntính\n \ntoàn\n \nvẹn\n \nvà\n \nliên\n \ntục\n \ncủa\n \nworkflow\n \nngay\n \ncả\n \nkhi\n \ncó\n \nnode\n \ngặp\n \nlỗi.\n \nƯu  điểm  của  CeleryExecutor  \nCeleryExecutor  nổi  bật  với  khả  năng  mở  rộng  linh  hoạt  (scalability) .  Chỉ  cần  thêm  hoặc  bớt  worker,  \nbạn\n \ncó\n \nthể\n \nnhanh\n \nchóng\n \nthích\n \nứng\n \nvới\n \nkhối\n \nlượng\n \ncông\n \nviệc\n \nthay\n \nđổi.\n \nHơn\n \nnữa,\n \nnó\n \ntăng\n \nkhả\n \nnăng\n \nchịu\n \nlỗi\n:\n \nnếu\n \nmột\n \nworker\n \nngừng\n \nhoạt\n \nđộng,\n \ncác\n \nworker\n \nkhác\n \nsẽ\n \ntiếp\n \nnhận\n \nphần\n \nviệc\n \ncòn\n \nlại\n \nmà\n \nkhông\n \nlàm\n \ngián', 'nguyên\n \nhiệu\n \nquả.\n \nTuy\n \nnhiên,\n \nvới\n \nhệ\n \nthống\n \nnhỏ\n \nhoặc\n \nmôi\n \ntrường\n \nthử\n \nnghiệm,\n \nviệc\n \ndùng\n \nCeleryExecutor\n \ncó\n \nthể\n \ngây\n \ndư\n \nthừa\n \nvì\n \nyêu\n \ncầu\n \nhạ\n \ntầng\n \nphức\n \ntạp\n \nhơn\n \nLocalExecutor.\n \nKhi  một  DAG  được  trigger,  Scheduler  phân  tích  các  task  đủ  điều  kiện  chạy  và  gửi  lệnh  thực  thi  \n(execute_async)  vào  message  broker .  Broker  xếp  các  lệnh  này  vào  queue  tương  ứng.  Các  worker  –', 'ngừng\n \nhoạt\n \nđộng,\n \ncác\n \nworker\n \nkhác\n \nsẽ\n \ntiếp\n \nnhận\n \nphần\n \nviệc\n \ncòn\n \nlại\n \nmà\n \nkhông\n \nlàm\n \ngián\n \nđoạn\n \ntoàn\n \nhệ\n \nthống.\n \nNgoài\n \nra,\n \nviệc\n \nsử\n \ndụng\n \nnhiều\n \nqueue\n \ngiúp\n \nbạn\n \nphân\n \nloại\n \nvà\n \nưu\n \ntiên\n \ntask\n \n—\n \nví\n \ndụ:\n \nqueue\n \ndành\n \ncho\n \ntác\n \nvụ\n \nnhẹ,\n \nqueue\n \ndành\n \ncho\n \ntác\n \nvụ\n \nnặng.\n \nTính\n \nlinh\n \nhoạt\n \nnày\n \nkhiến\n \nCeleryExecutor\n \ntrở\n \nthành\n \ntiêu\n \nchuẩn\n \nphổ\n \nbiến\n \nnhất\n \ntrong\n \ncác\n \nhệ\n \nthống\n \nAirflow\n \nproduction.\n \nNhược  điểm  của  CeleryExecutor  \nĐiểm  yếu  lớn  nhất  của  CeleryExecutor  là  độ  phức  tạp  trong  triển  khai  và  vận  hành .  Bạn  phải  cài  đặt  \nvà\n \nquản\n \nlý\n \nthêm\n \nmessage\n \nbroker,\n \nresult\n \nbackend,\n \nvà\n \nnhiều\n \nworker\n \nnode.\n \nTất\n \ncả\n \ncác\n \nworker\n \ncần\n \ncó\n \ncùng\n \nmôi\n \ntrường,\n \ncùng\n \nDAGs,\n \ncùng\n \ndependencies\n \n—\n \nnếu\n \nsai\n \nkhác\n \nnhỏ\n \ncũng\n \ncó\n \nthể\n \nkhiến\n \ntask\n \nthất\n \nbại.\n \nNgoài\n \nra,\n \nviệc\n \ngiám\n \nsát\n \n(monitoring)\n \nhệ\n \nthống\n \nCelery\n \nphức\n \ntạp', 'vụ\n \nvà\n \nthực\n \nthi\n \nđộc\n \nlập.\n \nMô\n \nhình\n \nnày\n \ngiúp\n \nAirflow\n \ncó\n \nthể\n \nxử\n \nlý\n \nsong\n \nsong\n \nkhối\n \nlượng\n \ncông\n \nviệc\n \nrất\n \nlớn,\n \nvượt\n \nxa\n \ngiới\n \nhạn\n \ncủa\n \nmột\n \nnode\n \nduy\n \nnhất.\n \nCeleryExecutor  phù  hợp  trong  các  môi  trường  production  quy  mô  lớn ,  nơi  có  nhiều  DAG  phức  tạp  và  \nhàng\n \ntrăm\n \nhoặc\n \nhàng\n \nnghìn\n \ntask\n \nchạy\n \nđồng\n \nthời.\n \nKhi\n \nworkload\n \ntăng,\n \nbạn\n \nchỉ\n \ncần\n \nthêm\n \ncác\n \nworker\n \nnode\n \nđể\n \nmở\n \nrộng\n \nhệ\n \nthống\n \n—\n \nđiều\n \nnày\n \ngọi\n \nlà\n \nscale-out\n \n(mở\n \nrộng\n \nngang).\n \nExecutor\n \nnày\n \ncũng\n \ntăng\n \ntính\n \nchịu\n \nlỗi\n \n(fault\n \ntolerance)\n:\n \nnếu\n \nmột\n \nworker\n \ngặp\n \nsự\n \ncố,\n \ncác\n \nworker\n \nkhác\n \nvẫn\n \ncó\n \nthể\n \ntiếp\n \ntục\n \nxử\n \nlý\n \nphần\n \ncông\n \nviệc\n \ncòn\n \nlại.\n \nNgoài\n \nra,\n \nnó\n \nhỗ\n \ntrợ\n \nphân\n \nloại\n \ntask\n \nqua\n \nnhiều\n \nhàng\n \nđợi\n \nkhác\n \nnhau,\n \ngiúp\n \nđiều\n \nphối\n \ntài\n \nnguyên\n \nhiệu\n \nquả.\n \nTuy\n \nnhiên,\n \nvới\n \nhệ\n \nthống\n \nnhỏ\n \nhoặc\n \nmôi\n \ntrường\n \nthử\n \nnghiệm,\n \nviệc\n \ndùng', 'Ngoài\n \nra,\n \nnếu\n \nmáy\n \nchủ\n \ngặp\n \nsự\n \ncố,\n \ntoàn\n \nbộ\n \npipeline\n \nsẽ\n \ndừng\n \nlại\n \n—\n \nkhông\n \ncó\n \nkhả\n \nnăng\n \nchịu\n \nlỗi\n \nhoặc\n \nkhôi\n \nphục\n \ntự\n \nđộng\n \nnhư\n \ncác\n \nexecutor\n \nphân\n \ntán.\n \nViệc\n \nchạy\n \nquá\n \nnhiều\n \nprocess\n \nsong\n \nsong\n \ncũng\n \ncó\n \nthể\n \nkhiến\n \nhệ\n \nđiều\n \nhành\n \nvà\n \ncơ\n \nsở\n \ndữ\n \nliệu\n \nbị\n \nnghẽn\n \nkết\n \nnối.\n \nCeleryExecutor  \nCeleryExecutor  là  một  loại  executor  trong  Apache  Airflow  cho  phép  phân  tán  việc  thực  thi  task  ra  \nnhiều\n \nmáy\n \n(worker\n \nnode)\n \nkhác\n \nnhau.\n \nThay\n \nvì\n \nScheduler\n \ntrực\n \ntiếp\n \nchạy\n \ntask\n \ntrên\n \ncùng\n \nmáy\n \nnhư\n \nLocalExecutor,\n \nCeleryExecutor\n \nsử\n \ndụng\n \nmột\n \nhệ\n \nthống\n \ntrung\n \ngian\n \ngọi\n \nlà\n \nmessage\n \nbroker\n \n(thường\n \nlà\n \nRedis\n \nhoặc\n \nRabbitMQ)\n \nđể\n \ngửi\n \ncác\n \nnhiệm\n \nvụ\n \ntới\n \ncác\n \nworker.\n \nMỗi\n \nworker\n \nlắng\n \nnghe\n \nhàng\n \nđợi\n \n(queue),\n \nnhận\n \nnhiệm\n \nvụ\n \nvà\n \nthực\n \nthi\n \nđộc\n \nlập.\n \nMô\n \nhình\n \nnày\n \ngiúp\n \nAirflow\n \ncó\n \nthể\n \nxử\n \nlý\n \nsong\n \nsong\n \nkhối', 'công\n \nviệc\n \ncần\n \nthực\n \nhiện\n.\n \nNói\n \ncách\n \nkhác,\n \nmột\n \nOperator\n \nchính\n \nlà\n \n“class”\n \ncòn\n \nTask\n \nlà\n \n“instance”\n \nđược\n \nsử\n \ndụng\n \ntrong\n \nDAG.\n \nAirflow  cung  cấp  nhiều  loại  Operator  khác  nhau,  được  chia  theo  mục  đích  sử  dụng:  \nNhóm  Ví  dụ  Chức  năng  \nCore  Operators  \nPythonOperator,  BashOperator,  EmailOperator \nThực  thi  script  Python,  command  shell,  gửi  email,  v.v.  \nTransfer  Operators  \nS3ToRedshiftOperator,  MySqlToGCSOperator \nDi  chuyển  dữ  liệu  giữa  các  nó  hệ  thống.  \nAction  Operators  \nSparkSubmitOperator,  DockerOperator,  KubernetesPodOperator \nChạy  job  xử  lý  dữ  liệu  hoặc  container  trên  các  nền  tảng  khác  nhau.  \nSensor  Operators  \nFileSensor,  ExternalTaskSensor \nChờ  đợi  một  điều  kiện  xảy  ra  (ví  dụ:  file  xuất  hiện,  task  khác  hoàn  tất).', 'Kiến  trúc  phân  tán  (Distributed  Architecture)  \n \nAirflow  được  thiết  kế  theo  mô  hình  phân  tán  (distributed) ,  tách  biệt  giữa  lập  lịch  (Scheduler)  và  thực  \nthi\n \n(Workers)\n.\n \nTrong\n \nmột\n \ntriển\n \nkhai\n \nproduction\n \nđiển\n \nhình,\n \ncác\n \nthành\n \nphần\n \ncó\n \nthể\n \nnằm\n \ntrên\n \ncác\n \nmáy\n \nchủ\n \nriêng\n \nbiệt:\n \n●  Node  A:  Scheduler  ●  Node  B:  Webserver  ●  Node  C:  Metadata  Database  ●  Node  D:  Message  Broker  (Redis/RabbitMQ)  ●  Nhiều  Node  khác:  Workers  (xử  lý  task  song  song)  \nEdge  Worker  trong  Apache  Airflow  là  một  node  worker  “phân  tán”  được  triển  khai  tại  vị  trí  biên  (edge  \nsite)\n,\n \ncho\n \nphép\n \nthực\n \nthi\n \ncác\n \ntác\n \nvụ\n \nngay\n \ngần\n \nnguồn\n \ndữ\n \nliệu\n \nthay\n \nvì\n \ntại\n \ntrung\n \ntâm\n \ndữ\n \nliệu\n \nchính.\n \nNó\n \nkết\n \nnối\n \nvới\n \ncluster\n \ntrung\n \ntâm\n \nqua\n \nHTTP(S)\n \nmà\n \nkhông\n \ncần\n \nmessage\n \nbroker,\n \ngiúp\n \nvượt\n \nqua\n \ncác\n \nrào\n \ncản\n \nmạng\n \nnhư\n \nfirewall\n \nhoặc\n \nNAT.\n \nTrong\n \nkiến\n \ntrúc\n \nphân\n \ntán,', 'việc\n \nkhởi\n \ntạo\n \nPod\n \nmới\n \ncó\n \nthể\n \ngây\n \nđộ\n \ntrễ\n \nnhất\n \nđịnh,\n \nđặc\n \nbiệt\n \nkhi\n \ncluster\n \nbận\n \nhoặc\n \nimage\n \ncontainer\n \nlớn.\n \nƯu  điểm  của  KubernetesExecutor  \nKubernetesExecutor  mang  lại  nhiều  lợi  ích  vượt  trội  so  với  các  executor  khác.  Thứ  nhất,  nó  cho  phép  \nmở\n \nrộng\n \nlinh\n \nhoạt\n \n–\n \nkhi\n \nsố\n \nlượng\n \ntask\n \ntăng,\n \nhệ\n \nthống\n \ncó\n \nthể\n \ntự\n \nđộng\n \ntạo\n \nthêm\n \nPod\n \nđể\n \nxử\n \nlý\n \nmà\n \nkhông\n \ncần\n \ncan\n \nthiệp\n \nthủ\n \ncông.\n \nThứ\n \nhai,\n \nnó\n \nđảm\n \nbảo\n \ncách\n \nly\n \ntài\n \nnguyên\n \ntuyệt\n \nđối:\n \nmỗi\n \ntask\n \nchạy\n \ntrong\n \ncontainer\n \nriêng\n \nnên\n \nkhông\n \nảnh\n \nhưởng\n \nđến\n \ntask\n \nkhác.\n \nThứ\n \nba,\n \nviệc\n \ntích\n \nhợp\n \nsâu\n \nvới\n \nhệ\n \nsinh\n \nthái\n \nKubernetes\n \ngiúp\n \ntận\n \ndụng\n \ncác\n \ntính\n \nnăng\n \nnhư\n \nautoscaling,\n \nnode\n \nscheduling,\n \nvà\n \nresource\n \nquota.\n \nNgoài\n \nra,\n \nsau\n \nkhi\n \ntask\n \nkết\n \nthúc,\n \nPod\n \nđược\n \ntự\n \nđộng\n \ndọn\n \ndẹp,\n \ngiúp\n \ngiảm\n \nthiểu\n \nchi\n \nphí\n \ntài\n \nnguyên\n \nkhông\n \ncần\n \nthiết.', 'Motivation  for  Using  Airflow  in  Big  Data  Analysis  \n1.  Bối  cảnh  –  Những  vấn  đề  cần  giải  quyết  \nKhi  các  tổ  chức  bắt  đầu  thu  thập  và  khai  thác  lượng  dữ  liệu  khổng  lồ  từ  nhiều  nguồn  khác  nhau  \n—\n \ncơ\n \nsở\n \ndữ\n \nliệu,\n \nlog\n \nhệ\n \nthống,\n \ndịch\n \nvụ\n \nweb,\n \nthiết\n \nbị\n \nIoT,\n \nvà\n \nnền\n \ntảng\n \nđám\n \nmây\n \n—\n \nnhu\n \ncầu\n \nquản\n \nlý\n \ncác\n \nquy\n \ntrình\n \nxử\n \nlý\n \ndữ\n \nliệu\n \ntrở\n \nnên\n \nvô\n \ncùng\n \nphức\n \ntạp.\n \nMỗi\n \nquy\n \ntrình\n \n(pipeline)\n \nthường\n \nbao\n \ngồm\n \nnhiều\n \nbước\n \nnhư\n \ntrích\n \nxuất\n \ndữ\n \nliệu\n \n(Extract),\n \nlàm\n \nsạch\n \nvà\n \nchuyển\n \nđổi\n \n(Transform),\n \nsau\n \nđó\n \ntải\n \nlên\n \nhệ\n \nthống\n \nlưu\n \ntrữ\n \nhoặc\n \nkho\n \ndữ\n \nliệu\n \n(Load).\n \nTrong\n \nmôi\n \ntrường\n \ndữ\n \nliệu\n \nlớn,\n \ncác\n \nbước\n \nnày\n \nkhông\n \nchỉ\n \nphải\n \nđược\n \nthực\n \nhiện\n \nđúng\n \nthứ\n \ntự\n \nvà\n \nđúng\n \nthời\n \nđiểm\n,\n \nmà\n \ncòn\n \nphải\n \nđảm\n \nbảo\n \nhiệu\n \nnăng,\n \nđộ\n \ntin\n \ncậy\n \nvà\n \nkhả\n \nnăng\n \nmở\n \nrộng\n \ntrên\n \nnhiều\n \nmáy\n \nchủ\n \nhoặc\n \ncụm\n \nxử\n \nlý\n \nphân\n \ntán', 'Scheduler  và  các  process  của  LocalExecutor  phải  chia  sẻ  tài  nguyên  —  nếu  máy  không  đủ  mạnh,  hiệu  \nsuất\n \ncủa\n \nScheduler\n \ncó\n \nthể\n \nbị\n \nảnh\n \nhưởng.\n Số  lượng  task  có  thể  chạy  cùng  lúc  phụ  thuộc  vào  tham  số  parallelism (số  process  tối  đa  cho  phép  \ncùng\n \nhoạt\n \nđộng).\n \nLocalExecutor  có  hai  chế  độ  hoạt  động  tùy  thuộc  vào  cấu  hình  parallelism:  \n●  Chế  độ  không  giới  hạn  (Unlimited  Parallelism) :   Khi  bạn  đặt  parallelism  =  0 \n“Không  giới  hạn  số  process  —  cứ  có  task  là  tạo  process  mới  để  chạy.”  \nAirflow  Scheduler  gửi  1  task  →  LocalExecutor  tạo  1  process  riêng  biệt  (LocalWorker)  để  \nxử\n \nlý.\n \nKhi\n \ntask\n \nxong\n \n→\n \nprocess\n \nđó\n \ntự\n \ntắt\n.\n \nTask\n \ntiếp\n \ntheo\n \n→\n \ntạo\n \nprocess\n \nmới\n \nkhác\n.\n \nGiả  sử  bạn  có  100  task  cùng  lúc :']","**Sự khác biệt giữa LocalExecutor và CeleryExecutor**

1. **Kiến trúc và Lập lịch**: LocalExecutor được thiết kế để chạy trong một môi trường đơn lõi, nơi Scheduler và thực thi của nó chia sẻ tài nguyên cùng nhau. Trong khi đó, CeleryExecutor được thiết kế theo mô hình phân tán với tách biệt giữa lập lịch (Scheduler) và thực thi (Workers).

2. **Phương thức hoạt động**: LocalExecutor tạo một process riêng biệt cho mỗi task được gửi từ Scheduler. Điều này có thể ảnh hưởng đến hiệu suất nếu máy chủ không đủ mạnh. Trong khi đó, CeleryExecutor cho phép chạy nhiều tasks song song trên nhiều nodes khác nhau thông qua cơ chế phân tán.

3. **Giới hạn và hiệu suất**: LocalExecutor yêu cầu chia sẻ tài nguyên giữa Scheduler và Worker process. Nếu số lượng task tăng lên và máy chủ không đủ mạnh để hỗ trợ, hiệu suất có thể giảm xuống. Trong khi đó, CeleryExecutor cho phép mở rộng linh hoạt hơn bằng cách tự động tạo thêm Pod nếu số lượng task tăng lên.

4. **Môi trường và khả năng mở rộng**: LocalExecutor hoạt động tốt trong một môi trường đơn lõi nhưng giới hạn về khả năng mở rộng trong trường hợp có quá nhiều tasks cần xử lý cùng lúc. CeleryExecutor, với khung làm việc phân tán, cho phép mở rộng khả năng xử lý của mình bằng cách thêm nodes khi cần thiết.

5. **Quản lý và giám sát**: LocalExecutor và CeleryExecutor đều cung cấp cơ chế để quản lý và giám sát các task chạy trong hệ thống, nhưng Celery Executor hỗ trợ hơn nhiều tính năng như autoscaling và resource quotas thông qua việc tích hợp với Kubernetes. 

6. **Tiến trình xử lý**: Với LocalExecutor, mỗi task được xử lý bởi một process riêng biệt và sau khi hoàn thành thì process đó tự động tắt. Trong trường hợp CeleryExecutor, mỗi task có thể chạy song song trên nhiều nodes mà không làm ảnh hưởng đến các task khác nhờ cơ chế độc lập của từng container hoặc Pod.

Vì vậy, so sánh LocalExecutor và CeleryExecutor cho thấy sự khác biệt trong cách họ xử lý và quản lý tasks cũng như khung công nghệ và khả năng mở rộng của chúng.","LocalExecutor chạy các task ngay trên cùng một máy với Scheduler, thiết lập đơn giản nhưng giới hạn tài nguyên và khả năng mở rộng. Ngược lại, CeleryExecutor sử dụng message broker để phân tán task ra nhiều máy worker khác nhau, cho phép mở rộng quy mô lớn (scale-out) và tăng khả năng chịu lỗi.",,0.9398053271717973,0.9888888888779013,
4,DAG trong Airflow là gì và ý nghĩa của tính chất 'Acyclic'?,DAG trong Airflow là gì và ý nghĩa của tính chất 'Acyclic'?,"['nút,\n \nmiễn\n \nlà\n \nluôn\n \ntuân\n \ntheo\n \nhướng\n \ncủa\n \ncác\n \ncạnh.\n \n“Acyclic”\n \nnghĩa\n \nlà\n \nkhông\n \ntồn\n \ntại\n \nvòng\n \nlặp\n \n—\n \nmột\n \ntask\n \nkhông\n \nthể\n \nphụ\n \nthuộc\n \nngược\n \nlại\n \nchính\n \nnó.\n \nĐiều\n \nnày\n \nđảm\n \nbảo\n \nrằng\n \nmỗi\n \nworkflow\n \ncó\n \nđiểm\n \nbắt\n \nđầu\n \nvà\n \nkết\n \nthúc\n \nxác\n \nđịnh,\n \ntránh\n \ncác\n \nvòng\n \nlặp\n \nvô\n \nhạn\n \ntrong\n \nxử\n \nlý.\n \nVề\n \nbản\n \nchất,\n \nDAG\n \ntrong\n \nAirflow\n \nlà\n \nmột\n \nđồ\n \nthị\n \ncó\n \nhướng\n \nvà\n \nkhông\n \nchu\n \ntrình\n,\n \nđược\n \nđịnh\n \nnghĩa\n \nbằng\n \nmã\n \nPython\n,\n \ncho\n \nphép\n \nngười\n \ndùng\n \nbiểu\n \ndiễn\n \nvà\n \nđiều\n \nkhiển\n \nluồng\n \nxử\n \nlý\n \ndữ\n \nliệu\n \nmột\n \ncách\n \nlinh\n \nhoạt,\n \ncó\n \nthể\n \nkiểm\n \nthử,\n \nvà\n \ndễ\n \ndàng\n \nquản\n \nlý\n \nphiên\n \nbản\n \n(version\n \ncontrol).\n \nVai  trò  trung  tâm  của  DAG  trong  Airflow  \nDAG  được  xem  là  trung  tâm  của  kiến  trúc  Airflow  vì  nó  chính  là  “ngôn  ngữ  chung”  để  mô  tả,  lập  lịch,  \nvà\n \nđiều\n \nphối\n \ncác\n \nluồng\n \ncông\n \nviệc.\n \nThay\n \nvì\n \nphải\n \nchạy\n \nthủ\n \ncông\n \ncác\n \nscript', 'tốn\n \nchi\n \nphí\n \nnhất\n \nđịnh.\n \nDAG  (Directed  Acyclic  Graph)  \nKhái  niệm  DAG  trong  Airflow  \nTrong  Apache  Airflow,  DAG  (Directed  Acyclic  Graph)  là  trái  tim  của  hệ  thống ,  dùng  để  mô  tả  một  \nworkflow\n \n(luồng\n \ncông\n \nviệc)\n \ngồm\n \nnhiều\n \ntác\n \nvụ\n \n(tasks)\n \nvà\n \nmối\n \nquan\n \nhệ\n \ngiữa\n \nchúng.\n \nDAG\n \ncho\n \nbiết\n \nnhững\n \ntác\n \nvụ\n \nnào\n \ncần\n \nchạy,\n \nkhi\n \nnào\n \nchạy,\n \nvà\n \ntheo\n \nthứ\n \ntự\n \nnào\n.\n \n“Directed”\n \nnghĩa\n \nlà\n \ncác\n \ntác\n \nvụ\n \ncó\n \nhướng\n \nthực\n \nthi\n \nrõ\n \nràng\n \n(task\n \nA\n \nchạy\n \ntrước\n \ntask\n \nB).\n \nMột\n \nđường\n \ndẫn\n \n(path)\n \nlà\n \nmột\n \nchuỗi\n \ncác\n \nnút\n \nđược\n \nkết\n \nnối\n \nbởi\n \ncác\n \ncạnh\n \ncó\n \nhướng,\n \nbắt\n \nđầu\n \ntừ\n \nmột\n \nnút\n \ncụ\n \nthể\n \nvà\n \ntheo\n \nhướng\n \ncủa\n \ncác\n \ncạnh\n \nđể\n \nđến\n \nmột\n \nnút\n \nkhác.\n \nĐường\n \ndẫn\n \ncó\n \nthể\n \ncó\n \nđộ\n \ndài\n \nbất\n \nkỳ,\n \ntừ\n \nmột\n \nnút\n \nđơn\n \nlẻ\n \nđến\n \nmột\n \nchuỗi\n \nnhiều\n \nnút,\n \nmiễn\n \nlà\n \nluôn\n \ntuân\n \ntheo\n \nhướng\n \ncủa\n \ncác\n \ncạnh.\n \n“Acyclic”\n \nnghĩa\n \nlà\n \nkhông\n \ntồn\n \ntại', 'Executor  và  Worker  chịu  trách  nhiệm  chạy  chúng.  Bằng  cách  này,  Airflow  có  thể  mở  rộng  quy  mô  linh  \nhoạt,\n \nquản\n \nlý\n \nsong\n \nsong\n \nhàng\n \ntrăm\n \npipeline\n \nkhác\n \nnhau.\n \nNgoài\n \nra,\n \nDAG\n \ncòn\n \ngiúp\n \nhiển\n \nthị\n \ntoàn\n \nbộ\n \ncấu\n \ntrúc\n \nworkflow\n \ntrên\n \ngiao\n \ndiện\n \nWeb\n \nUI,\n \ngiúp\n \nnhóm\n \nkỹ\n \nsư\n \ndữ\n \nliệu\n \ntheo\n \ndõi,\n \nquản\n \nlý,\n \nvà\n \nkhắc\n \nphục\n \nsự\n \ncố\n \ndễ\n \ndàng\n \ntrong\n \nhệ\n \nthống\n \nBig\n \nData\n \nphức\n \ntạp.\n \nMột  DAG  trong  Airflow  gồm  nhiều  thành  phần  cấu  trúc  cốt  lõi.  Đầu  tiên  là  DAG  object ,  được  khai  báo  \ntrong\n \nmã\n \nPython\n \nvới\n \ncác\n \ntham\n \nsố\n \nnhư\n dag_id (định  danh  DAG),  start_date (ngày  bắt  đầu),  schedule (chu  kỳ  chạy),  default_args (các  tham  số  mặc  định  cho  tasks),  và  catchup (xác  định  có  \nchạy\n \nbù\n \nnhững\n \nlần\n \nbị\n \nbỏ\n \nlỡ\n \nhay\n \nkhông).\n \nNgoài\n \nra,\n \nDAG\n \ncòn\n \ncó\n \ncác\n \nthuộc\n \ntính\n \nđiều\n \nkhiển\n \nnhư', 'những\n \nlần\n \nbị\n \nbỏ\n \nlỡ\n \nhay\n \nkhông).\n \nNgoài\n \nra,\n \nDAG\n \ncòn\n \ncó\n \ncác\n \nthuộc\n \ntính\n \nđiều\n \nkhiển\n \nnhư\n max_active_runs,  tags,  retry_delay,  hoặc  callback  khi  task  thất  bại.  Khi  được  Scheduler  quét,  \nDAG\n \nsẽ\n \nđược\n \nphân\n \ntích\n \nđể\n \nbiết\n \nthứ\n \ntự\n \nchạy,\n \nlịch\n \ntrình\n \nvà\n \nđiều\n \nkiện\n \nphụ\n \nthuộc\n \ngiữa\n \ncác\n \ntác\n \nvụ.\n \nTasks  /  Operators  trong  Airflow  \nTrong  Airflow,  Task  là  đơn  vị  công  việc  nhỏ  nhất  trong  một  DAG  —  mỗi  task  đại  diện  cho  một  hành  \nđộng\n \ncụ\n \nthể\n \ncần\n \nđược\n \nthực\n \nthi,\n \nví\n \ndụ\n \nnhư\n \nchạy\n \nmột\n \nđoạn\n \nmã\n \nPython,\n \ntải\n \ndữ\n \nliệu\n \ntừ\n \nAPI,\n \nnạp\n \ndữ\n \nliệu\n \nvào\n \ncơ\n \nsở\n \ndữ\n \nliệu,\n \nhay\n \nkhởi\n \nchạy\n \nmột\n \njob\n \ntrên\n \nSpark\n \nhoặc\n \nHadoop.\n \nVề\n \nbản\n \nchất,\n \nTasks\n \nđược\n \ntạo\n \nra\n \ntừ\n \ncác\n \nOperators\n,\n \ntức\n \nlà\n \nmẫu\n \n(template)\n \nđịnh\n \nnghĩa\n \nloại\n \ncông\n \nviệc\n \ncần\n \nthực\n \nhiện\n.\n \nNói\n \ncách\n \nkhác,\n \nmột\n \nOperator\n \nchính\n \nlà\n \n“class”\n \ncòn\n \nTask\n \nlà', 'Hạn  chế  của  kiến  trúc  Airflow  \nMặc  dù  mạnh  mẽ,  kiến  trúc  Airflow  vẫn  có  một  số  hạn  chế  đáng  chú  ý :  \n●  Không  phù  hợp  cho  xử  lý  real-time  (thời  gian  thực) :  Airflow  được  thiết  kế  cho  batch  \nprocessing\n \n(xử\n \nlý\n \ntheo\n \nlô),\n \nnên\n \nkhông\n \ntối\n \nưu\n \ncho\n \ndữ\n \nliệu\n \nstreaming\n \ncó\n \nđộ\n \ntrễ\n \nthấp\n \nnhư\n \nKafka\n \nhoặc\n \nFlink.\n ●  Độ  phức  tạp  trong  triển  khai :  Khi  hệ  thống  lớn,  việc  quản  lý  nhiều  node  (Scheduler,  Worker,  \nDatabase,\n \nBroker)\n \ntrở\n \nnên\n \nkhó\n \nkhăn;\n \ncần\n \nkỹ\n \nnăng\n \nDevOps\n \ntốt\n \nđể\n \nvận\n \nhành\n \nổn\n \nđịnh.\n ●  Phụ  thuộc  vào  cơ  sở  dữ  liệu  trung  tâm :  Nếu  Metadata  Database  bị  nghẽn  hoặc  lỗi,  toàn  bộ  \nAirflow\n \ncó\n \nthể\n \nbị\n \nảnh\n \nhưởng.\n ●  Không  tối  ưu  cho  workflow  quá  nhỏ  hoặc  thay  đổi  liên  tục ,  vì  việc  parse  và  schedule  DAG  \ntốn\n \nchi\n \nphí\n \nnhất\n \nđịnh.\n \nDAG  (Directed  Acyclic  Graph)  \nKhái  niệm  DAG  trong  Airflow', 'đảm\n \nbảo\n \nrằng\n \ncác\n \ncông\n \nviệc\n \nđược\n \nthực\n \nhiện\n \nđúng\n \nlogic\n \n—\n \nví\n \ndụ,\n \nbạn\n \nphải\n \n“extract\n \ndữ\n \nliệu”\n \nxong\n \nmới\n \ncó\n \nthể\n \n“transform”,\n \nrồi\n \nmới\n \n“load”\n \nvào\n \nkho\n \ndữ\n \nliệu.\n \nAirflow\n \ncho\n \nphép\n \nđịnh\n \nnghĩa\n \ndependencies\n \ngiữa\n \ncác\n \ntask\n \nmột\n \ncách\n \nlinh\n \nhoạt,\n \nthông\n \nqua\n \ntoán\n \ntử\n \nhướng\n \n(>> và  <<)  hoặc  các  hàm  set_upstream()  /  set_downstream() .  \nVí  dụ:  \nextract  >>  transform  >>  load  \nCâu  lệnh  trên  tương  đương  với:  \ntransform.set_upstream(extract)  load.set_upstream(transform)  \nDependencies  trong  Airflow  không  chỉ  giúp  đảm  bảo  tính  logic  của  pipeline  mà  còn  giúp  tận  dụng  \nsong\n \nsong\n \nhóa\n:\n \ncác\n \ntask\n \nkhông\n \nphụ\n \nthuộc\n \nnhau\n \ncó\n \nthể\n \nchạy\n \nđồng\n \nthời\n \ntrên\n \ncác\n \nworker\n \nkhác\n \nnhau,\n \ngiúp\n \ntối\n \nưu\n \nthời\n \ngian\n \nxử\n \nlý.\n \nCách  vận  hành  và  ví  dụ  minh  họa  của  DAG', 'Custom  Operators  \nNgười  dùng  tự  định  nghĩa  subclass  Operator  riêng  \nDùng  cho  logic  nghiệp  vụ  cụ  thể  hoặc  tích  hợp  hệ  thống  nội  bộ.  \nVí  dụ,  một  task  dùng  PythonOperator  có  thể  được  định  nghĩa  như  sau:  \nfrom  airflow.operators.python  import  PythonOperator  \ndef  transform_data():  \nprint(""Transforming  data..."")  \ntransform_task  =  PythonOperator(  \ntask_id=\'transform_data\',  \n     python_callable=transform_data)  \n \nỞ  đây,  transform_task là  Task  Instance  của  Operator  PythonOperator.  Mỗi  Task  có  các  thuộc  \ntính\n \nquan\n \ntrọng\n \nnhư:\n \n●  task_id:  định  danh  duy  nhất  trong  DAG.  ●  python_callable (hoặc  bash_command…):  hành  động  cần  thực  thi.  ●  retries,  retry_delay:  cấu  hình  retry  khi  task  lỗi.  ●  depends_on_past:  quy  định  task  có  cần  chờ  phiên  bản  trước  của  chính  nó  hoàn  tất  không.', 'lớn\n \ndẫn\n \nđến\n \nhàng\n \ntrăm\n \nPod\n \nđược\n \ntạo\n \nvà\n \nxóa\n \nliên\n \ntục.\n \nƯu  điểm  và  nhược  điểm  của  Airflow  \nƯu  điểm   \n1.  “Workflow  as  Code”  –  Mọi  thứ  đều  là  mã  nguồn \nAirflow  cho  phép  bạn  định  nghĩa  toàn  bộ  pipeline  dữ  liệu  dưới  dạng  mã  Python.  Điều  này  không  \nchỉ\n \ngiúp\n \nbạn\n \nkiểm\n \nsoát\n \nlogic\n \nmột\n \ncách\n \nchi\n \ntiết\n \nmà\n \ncòn\n \ncho\n \nphép\n \ntái\n \nsử\n \ndụng,\n \nkiểm\n \nthử\n \nvà\n \nversion\n \nhóa\n \ndễ\n \ndàng.\n \nGiả\n \nsử\n \nbạn\n \ncần\n \nxử\n \nlý\n \ndữ\n \nliệu\n \ntừ\n \n30\n \nnguồn\n \nkhác\n \nnhau,\n \nmỗi\n \nnguồn\n \ncó\n \ncấu\n \ntrúc\n \nvà\n \ntham\n \nsố\n \nriêng.\n \nThay\n \nvì\n \ntạo\n \n30\n \nDAG\n \ntĩnh,\n \nbạn\n \ncó\n \nthể\n \nviết\n \nmột\n \nđoạn\n \nmã\n \nPython\n \nsử\n \ndụng\n \nvòng\n \nlặp', 'quay\n \nlại\n \nphiên\n \nbản\n \ntrước\n \ncủa\n \npipeline\n \nhoặc\n \nkhi\n \ncó\n \nsự\n \ncố\n \nxảy\n \nra.\n \nKhi\n \nchỉnh\n \nsửa\n \nmột\n \nDAG\n \nvà\n \ndeploy,\n \ncác\n \ntask\n \ncũ\n \ncó\n \nthể\n \nbị\n \nmất,\n \nvà\n \nkhông\n \nthể\n \ndễ\n \ndàng\n \nquay\n \nlại\n \ntrạng\n \nthái\n \ntrước\n \nđó.\n \n→\n \nNgười\n \ndùng\n \nnên\n \nquản\n \nlý\n \nDAGs\n \nbằng\n \nhệ\n \nthống\n \nkiểm\n \nsoát\n \nphiên\n \nbản\n \nnhư\n \nGit,\n \ntạo\n \nnhánh\n \nvà\n \ncommit\n \nthường\n \nxuyên\n \nđể\n \ncó\n \nthể\n \nquay\n \nlại\n \nphiên\n \nbản\n \ntrước\n \nkhi\n \ncần\n \nthiết.\n \n4.  Giám  sát  chất  lượng  dữ  liệu  hạn  chế \nAirflow  chủ  yếu  tập  trung  vào  việc  điều  phối  pipeline  và  không  cung  cấp  các  công  cụ  tích  hợp  sẵn  \nđể\n \nkiểm\n \ntra\n \nchất\n \nlượng\n \ndữ\n \nliệu.\n \nAirflow\n \ncó\n \nthể\n \nbáo\n \ncáo\n \nmột\n \ntask\n \nthành\n \ncông,\n \nnhưng\n \nkhông\n \nthể\n \nxác\n \nnhận\n \nliệu\n \ndữ\n \nliệu\n \nđầu\n \nra\n \ncó\n \nđúng\n \nđịnh\n \ndạng,\n \nkhông\n \ncó\n \ngiá\n \ntrị\n \nnull\n \nhay\n \nkhông.\n \n→\n \nNgười\n \ndùng\n \nnên\n \ntích\n \nhợp\n \ncác\n \ncông\n \ncụ\n \nkiểm\n \ntra\n \nchất\n \nlượng\n \ndữ\n \nliệu\n \nnhư\n \nGreat']","DAG trong Airflow là Directed Acyclic Graph, tức là một cấu trúc đồ thị có hướng không chứa cạnh kép. Trong ngữ cảnh của Airflow - hệ thống quản lý việc thực thi các công việc (tasks) để xử lý dữ liệu ở dạng batch processing, DAG có ý nghĩa quan trọng.

'Băng tính Acyclic' trong DAG có nghĩa là không tồn tại đường đi từ một task nào có thể trở lại lại trực tiếp hoặc gián tiếp thông qua các task khác mà không đi qua tất cả các task khác. Điều này đảm bảo rằng quá trình xử lý dữ liệu diễn ra theo lô, không được lặp lại hay tạo vòng lặp vô tận.

Ví dụ về việc sử dụng tính chất 'Acyclic' này có thể là quy trình chuẩn hóa dữ liệu sau khi đã extraxt dữ liệu từ nguồn dữ liệu và trước khi load vào kho dữ liệu. Điều này đảm bảo rằng quá trình xử lý dữ liệu diễn ra theo logic xác định, không bị lặp lại hoặc tạo thành vòng lặp.

Nói một cách đơn giản hơn, DAG trong Airflow giúp quản lý các công việc cần thực hiện từ đầu đến cuối với quy tắc chỉ cho phép mỗi công việc được thực hiện một lần và không thể tái xuất hiện sau cùng công việc đã hoàn thành.","DAG (Directed Acyclic Graph) là đồ thị có hướng không chu trình, dùng để mô tả workflow gồm nhiều task và mối quan hệ giữa chúng. 'Acyclic' nghĩa là không tồn tại vòng lặp, đảm bảo workflow luôn có điểm bắt đầu và kết thúc xác định, tránh việc task phụ thuộc ngược lại chính nó gây lặp vô hạn.",,0.9380263704796145,0.9704861110989801,
