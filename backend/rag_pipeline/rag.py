"""
RAG Pipeline - Káº¿t ná»‘i cÃ¡c components thÃ nh pipeline hoÃ n chá»‰nh
"""
from typing import Generator, List, Dict, Any, Optional
from ..config import settings
from ..ai_deps import get_embedder, get_reranker

# Import cÃ¡c components
from .embedder import Embedder
from .vector_store import VectorStore
from .retriever import Retriever
from .generator import generate_answer, generate_answer_stream
from .language_detector import LanguageDetector
from .prompt_builder import build_prompt
from .reranker import Reranker


class RAGRetriever:
    """
    Wrapper class cho Retriever Ä‘á»ƒ sá»­ dá»¥ng trong pipeline
    """
    def __init__(self, index_path: str, meta_path: str, embedder: Embedder = None):
        """
        Initialize retriever vá»›i saved vector store
        
        Args:
            index_path: ÄÆ°á»ng dáº«n file .index (FAISS)
            meta_path: ÄÆ°á»ng dáº«n file .json (text chunks)
            embedder: Embedder instance (optional, sáº½ táº¡o má»›i náº¿u None)
        """
        self.index_path = index_path
        self.meta_path = meta_path
        
        # Khá»Ÿi táº¡o embedder náº¿u chÆ°a cÃ³
        if embedder is None:
            self.embedder = get_embedder()
        else:
            self.embedder = embedder
        
        # Khá»Ÿi táº¡o retriever vá»›i embedder vÃ  store
        self.retriever = Retriever(
            store_path=index_path,
            meta_path=meta_path,
            embedder=self.embedder
        )
        
        print(f"âœ… Retriever initialized with {len(self.retriever.store.documents)} chunks")
    
    @staticmethod
    def _format_context(doc: Dict[str, Any]) -> str:
        metadata = doc.get("metadata", {})
        source_parts = []
        
        filename = metadata.get("filename")
        if filename:
            source_parts.append(f"Source: {filename}")
        elif metadata.get("source"):
            source_parts.append(f"Source: {metadata.get('source')}")
        
        page = metadata.get("page")
        if page is not None:
            source_parts.append(f"Page: {page}")
        
        chunk_id = metadata.get("chunk_unique_id") or metadata.get("chunk_id")
        if chunk_id:
            source_parts.append(f"Chunk: {chunk_id}")
        
        meta_line = " | ".join(source_parts) if source_parts else "Source: unknown"
        return f"[{meta_line}]\n{doc.get('text', '')}"
    
    def retrieve(
        self, 
        question: str, 
        k_semantic: int = None,
        k_keyword: int = None,
        use_validation: bool = True,
        allowed_document_ids: Optional[set[int]] = None
    ) -> Optional[List[str]]:
        """
        Retrieve relevant contexts cho cÃ¢u há»i
        
        Args:
            question: CÃ¢u há»i cá»§a user
            k_semantic: Sá»‘ lÆ°á»£ng contexts tá»« semantic search
            k_keyword: Sá»‘ lÆ°á»£ng contexts tá»« keyword search
            use_validation: CÃ³ validate relevance khÃ´ng
            
        Returns:
            List[str]: Danh sÃ¡ch text contexts, hoáº·c None náº¿u khÃ´ng tÃ¬m tháº¥y
        """
        if k_semantic is None:
            k_semantic = settings.TOP_K_RETRIEVE
        
        if k_keyword is None:
            k_keyword = settings.TOP_K_RETRIEVE
        
        try:
            if use_validation:
                # DÃ¹ng retrieve_with_validation - tráº£ vá» None náº¿u khÃ´ng relevant
                contexts = self.retriever.retrieve_with_validation(
                    query=question,
                    k_semantic=k_semantic,
                    k_keyword=k_keyword,
                    semantic_threshold=settings.SIMILARITY_THRESHOLD,
                    bm25_threshold=settings.BM25_THRESHOLD,
                    min_results=1,
                    bm25_min_top1=1.0
                )
            else:
                # Retrieve bÃ¬nh thÆ°á»ng
                contexts, is_relevant = self.retriever.retrieve(
                    query=question,
                    k_semantic=k_semantic,
                    k_keyword=k_keyword,
                    semantic_threshold=settings.SIMILARITY_THRESHOLD,
                    bm25_threshold=settings.BM25_THRESHOLD,
                    min_results=1,
                    bm25_min_top1=1.0
                )
                if not is_relevant:
                    contexts = None
            
            if contexts:
                if allowed_document_ids is not None:
                    contexts = [
                        doc
                        for doc in contexts
                        if doc.get("metadata", {}).get("document_id") in allowed_document_ids
                    ]
            
            if contexts:
                contexts = [self._format_context(doc) for doc in contexts]
            
            return contexts
            
        except Exception as e:
            print(f"âŒ Error in retrieval: {e}")
            return None


def create_retriever(index_path: str, meta_path: str, embedder: Embedder = None) -> RAGRetriever:
    """
    Factory function Ä‘á»ƒ táº¡o Retriever
    
    Args:
        index_path: ÄÆ°á»ng dáº«n file .index
        meta_path: ÄÆ°á»ng dáº«n file .json
        embedder: Embedder instance (optional)
        
    Returns:
        RAGRetriever instance
    """
    return RAGRetriever(index_path, meta_path, embedder)


def answer_question_with_store(
    question: str,
    retriever: RAGRetriever,
    streaming: bool = False,
    use_reranker: bool = False,
    reranker_top_k: int = 3,
    detect_language: bool = True,
    model: str = None,
    temperature: float = None,
    allowed_document_ids: Optional[set[int]] = None
) -> str | Generator[str, None, None]:
    """
    RAG Pipeline hoÃ n chá»‰nh: Retrieve + Generate
    
    Args:
        question: CÃ¢u há»i cá»§a user
        retriever: RAGRetriever instance
        streaming: True náº¿u muá»‘n stream response
        use_reranker: CÃ³ dÃ¹ng reranker khÃ´ng
        reranker_top_k: Sá»‘ contexts sau rerank
        detect_language: CÃ³ tá»± Ä‘á»™ng detect ngÃ´n ngá»¯ khÃ´ng
        model: LLM model name (override config)
        temperature: Temperature cho generation (override config)
        
    Returns:
        str náº¿u streaming=False
        Generator[str] náº¿u streaming=True
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“ Question: {question}")
    print(f"{'='*60}\n")
    
    # Step 1: Retrieve contexts
    print("ğŸ” Step 1: Retrieving contexts...")
    contexts = retriever.retrieve(
        question=question,
        k_semantic=settings.TOP_K_RETRIEVE,
        k_keyword=settings.TOP_K_RETRIEVE,
        use_validation=True,
        allowed_document_ids=allowed_document_ids
    )
    
    # Kiá»ƒm tra contexts
    if not contexts or len(contexts) == 0:
        print("âš ï¸  No relevant contexts found")
        no_context_answer = (
            "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong tÃ i liá»‡u "
            "Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i nÃ y. Vui lÃ²ng thá»­ há»i theo cÃ¡ch khÃ¡c hoáº·c "
            "kiá»ƒm tra láº¡i tÃ i liá»‡u Ä‘Ã£ upload."
        )
        
        if streaming:
            def no_context_generator():
                for char in no_context_answer:
                    yield char
            return no_context_generator()
        else:
            return no_context_answer
    
    print(f"âœ… Found {len(contexts)} contexts")
    
    # Step 2: Rerank contexts (optional)
    if use_reranker and len(contexts) > reranker_top_k:
        print(f"\nğŸ¯ Step 2: Reranking contexts (top {reranker_top_k})...")
        try:
            reranker = get_reranker()
            contexts = reranker.rerank(
                query=question,
                candidates=contexts,
                topn=reranker_top_k,
                score_threshold=0.3,
                return_scores=False
            )
            print(f"âœ… Reranked to {len(contexts)} contexts")
        except Exception as e:
            print(f"âš ï¸  Reranking failed: {e}. Using original contexts.")
    else:
        print(f"\nâ­ï¸  Step 2: Skipping reranker")
    
    # Step 3: Detect language
    language = "Vietnamese"  # Default
    if detect_language:
        print(f"\nğŸŒ Step 3: Detecting language...")
        try:
            detector = LanguageDetector()
            language = detector.detect(question)
            print(f"âœ… Detected language: {language}")
        except Exception as e:
            print(f"âš ï¸  Language detection failed: {e}. Using default: Vietnamese")
    else:
        print(f"\nâ­ï¸  Step 3: Using default language: Vietnamese")
    
    # Step 4: Build prompt
    print(f"\nğŸ“‹ Step 4: Building prompt...")
    prompt = build_prompt(
        question=question,
        contexts=contexts,
        language=language
    )
    print(f"âœ… Prompt built ({len(prompt)} chars)")
    
    # Step 5: Generate answer
    target_model = model or settings.LLM_MODEL
    
    print(f"\nğŸ¤– Step 5: Generating answer...")
    print(f"   Model: {target_model}")
    print(f"   Streaming: {streaming}")
    
    try:
        if streaming:
            print("âœ… Streaming response started\n")
            # LuÃ´n truyá»n target_model vÃ o hÃ m
            return generate_answer_stream(
                prompt, 
                model=target_model, 
                temperature=temperature or settings.GENERATOR_TEMPERATURE
            )
        else:
            # LuÃ´n truyá»n target_model vÃ o hÃ m
            answer = generate_answer(
                prompt, 
                model=target_model
            )
            print(f"âœ… Answer generated ({len(answer)} chars)\n")
            return answer
            
    except Exception as e:
        print(f"âŒ Generation failed: {e}")
        error_message = (
            "Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra khi táº¡o cÃ¢u tráº£ lá»i. "
            "Vui lÃ²ng thá»­ láº¡i sau."
        )
        
        if streaming:
            def error_generator():
                yield error_message
            return error_generator()
        else:
            return error_message


def answer_question_simple(
    question: str,
    retriever: RAGRetriever,
    streaming: bool = False
) -> str | Generator[str, None, None]:
    """
    Simplified RAG pipeline - khÃ´ng dÃ¹ng reranker, language detection Ä‘Æ¡n giáº£n
    
    Args:
        question: CÃ¢u há»i cá»§a user
        retriever: RAGRetriever instance
        streaming: True náº¿u muá»‘n stream response
        
    Returns:
        str náº¿u streaming=False
        Generator[str] náº¿u streaming=True
    """
    return answer_question_with_store(
        question=question,
        retriever=retriever,
        streaming=streaming,
        use_reranker=False,
        detect_language=True
    )


def answer_question_advanced(
    question: str,
    retriever: RAGRetriever,
    streaming: bool = False,
    reranker_top_k: int = 3
) -> str | Generator[str, None, None]:
    """
    Advanced RAG pipeline - cÃ³ reranker vÃ  language detection
    
    Args:
        question: CÃ¢u há»i cá»§a user
        retriever: RAGRetriever instance
        streaming: True náº¿u muá»‘n stream response
        reranker_top_k: Sá»‘ contexts sau rerank
        
    Returns:
        str náº¿u streaming=False
        Generator[str] náº¿u streaming=True
    """
    return answer_question_with_store(
        question=question,
        retriever=retriever,
        streaming=streaming,
        use_reranker=True,
        reranker_top_k=reranker_top_k,
        detect_language=True
    )


# Utility functions
def format_contexts_for_display(contexts: List[str], max_length: int = 200) -> List[str]:
    """
    Format contexts Ä‘á»ƒ hiá»ƒn thá»‹ (truncate náº¿u quÃ¡ dÃ i)
    
    Args:
        contexts: Danh sÃ¡ch contexts
        max_length: Äá»™ dÃ i tá»‘i Ä‘a má»—i context
        
    Returns:
        List contexts Ä‘Ã£ format
    """
    formatted = []
    for i, ctx in enumerate(contexts, 1):
        if len(ctx) > max_length:
            ctx_display = ctx[:max_length] + "..."
        else:
            ctx_display = ctx
        formatted.append(f"[Context {i}]: {ctx_display}")
    
    return formatted


def get_context_sources(contexts: List[str]) -> Dict[str, Any]:
    """
    TrÃ­ch xuáº¥t thÃ´ng tin nguá»“n tá»« contexts (náº¿u cÃ³)
    
    Args:
        contexts: Danh sÃ¡ch contexts
        
    Returns:
        Dict chá»©a thÃ´ng tin sources
    """
    return {
        "total_contexts": len(contexts),
        "total_chars": sum(len(c) for c in contexts),
        "avg_length": sum(len(c) for c in contexts) / len(contexts) if contexts else 0
    }


def validate_retriever_setup(index_path: str, meta_path: str) -> bool:
    """
    Kiá»ƒm tra xem retriever cÃ³ thá»ƒ Ä‘Æ°á»£c khá»Ÿi táº¡o khÃ´ng
    
    Args:
        index_path: ÄÆ°á»ng dáº«n file .index
        meta_path: ÄÆ°á»ng dáº«n file .json
        
    Returns:
        True náº¿u há»£p lá»‡, False náº¿u khÃ´ng
    """
    import os
    
    if not os.path.exists(index_path):
        print(f"âŒ Index file not found: {index_path}")
        return False
    
    if not os.path.exists(meta_path):
        print(f"âŒ Meta file not found: {meta_path}")
        return False
    
    try:
        # Thá»­ load Ä‘á»ƒ kiá»ƒm tra
        retriever = create_retriever(index_path, meta_path)
        print("âœ… Retriever validation successful")
        return True
    except Exception as e:
        print(f"âŒ Retriever validation failed: {e}")
        return False