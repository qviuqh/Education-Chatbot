"""
RAG Service - Orchestration RAG: build index, answer question
"""
from sqlalchemy.orm import Session
from fastapi import HTTPException, status
from typing import Generator, Optional
import os

from .. import models
from ..config import settings

# Import RAG components
from ..rag_pipeline.data_loader import load_document, chunk_documents
from ..rag_pipeline.embedder import Embedder
from ..rag_pipeline.vector_store import VectorStore
from ..ai_deps import get_embedder
from ..rag_pipeline.rag import (
    create_retriever, 
    answer_question_with_store,
    validate_retriever_setup
)


def build_vector_store_for_conversation(
    db: Session,
    conversation_id: int
) -> None:  # sourcery skip: extract-method
    """
    XÃ¢y dá»±ng vector store cho conversation
    
    Steps:
    1. Load táº¥t cáº£ documents cá»§a conversation
    2. Chunk documents thÃ nh cÃ¡c Ä‘oáº¡n nhá»
    3. Embed cÃ¡c chunks
    4. LÆ°u vÃ o FAISS index
    5. Cáº­p nháº­t VectorStoreMeta
    """
    print(f"\n{'='*60}")
    print(f"ğŸš€ Building vector store for conversation {conversation_id}")
    print(f"{'='*60}\n")
    
    # Láº¥y conversation vÃ  metadata
    conversation = db.query(models.Conversation).filter(
        models.Conversation.id == conversation_id
    ).first()
    
    if not conversation:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    vector_meta = conversation.vector_store_meta
    
    if not vector_meta:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Vector store metadata not found"
        )
    
    try:
        # Cáº­p nháº­t status
        vector_meta.status = "building"
        db.commit()
        print("ğŸ“ Status: building")
        
        # Step 1: Load vÃ  chunk documents
        print("\nğŸ“š Step 1: Loading and chunking documents...")
        all_texts = []
        doc_count = 0
        
        for conv_doc in conversation.documents:
            document = conv_doc.document
            
            # Kiá»ƒm tra file tá»“n táº¡i
            if not os.path.exists(document.filepath):
                print(f"âš ï¸  File not found: {document.filepath}")
                continue
            
            print(f"  ğŸ“„ Loading: {document.filename}")
            
            try:
                # Load document
                docs = load_document(document.filepath)
                print(f"     âœ… Loaded {len(docs)} pages")
                
                # Chunk documents
                chunks = chunk_documents(
                    docs, 
                    chunk_size=800,  # CÃ³ thá»ƒ config
                    overlap=120
                )
                print(f"     âœ… Created {len(chunks)} chunks")
                
                # Extract text tá»« chunks
                texts = [chunk.page_content for chunk in chunks]
                all_texts.extend(texts)
                doc_count += 1
                
            except Exception as e:
                print(f"     âŒ Error loading document: {e}")
                continue
        
        if not all_texts:
            raise Exception("No texts extracted from documents")
        
        print(f"\nâœ… Total: {len(all_texts)} chunks from {doc_count} documents")
        
        # Step 2: Embed texts
        print(f"\nğŸ”¢ Step 2: Embedding texts...")
        embedder = get_embedder()
        print(f"  Model: {settings.EMBEDDING_MODEL}")
        
        embeddings = embedder.encode(all_texts, prefix="passage")
        print(f"  âœ… Created embeddings: shape {embeddings.shape}")
        
        # Step 3: Create vÃ  save vector store
        print(f"\nğŸ’¾ Step 3: Creating vector store...")
        vector_store = VectorStore(
            dim=embedder.model.get_sentence_embedding_dimension(),
            path=vector_meta.index_path,
            meta_path=vector_meta.meta_path
        )
        
        print(f"  Index path: {vector_meta.index_path}")
        print(f"  Meta path: {vector_meta.meta_path}")
        
        vector_store.add(embeddings, all_texts)
        vector_store.save()
        print("  âœ… Vector store saved")
        
        # Step 4: Update metadata
        vector_meta.doc_count = len(all_texts)
        vector_meta.dimension = embedder.model.get_sentence_embedding_dimension()
        vector_meta.status = "ready"
        vector_meta.error_message = None
        
        db.commit()
        
        print(f"\n{'='*60}")
        print("âœ… Vector store built successfully!")
        print(f"   - Chunks: {len(all_texts)}")
        print(f"   - Dimension: {embedder.model.get_sentence_embedding_dimension()}")
        print("   - Status: ready")
        print(f"{'='*60}\n")
        
    except Exception as e:
        print(f"{'='*60}")
        print(f"âŒ Error building vector store: {e}")
        print(f"{'='*60}\n")
        
        # Cáº­p nháº­t lá»—i
        vector_meta.status = "error"
        vector_meta.error_message = str(e)
        db.commit()
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to build vector store: {str(e)}"
        )


def answer_question_for_conversation(
    db: Session,
    conversation_id: int,
    question: str,
    streaming: bool = False,
    use_reranker: bool = False
) -> str | Generator[str, None, None]:
    """
    Tráº£ lá»i cÃ¢u há»i cho conversation
    
    Args:
        db: Database session
        conversation_id: ID cá»§a conversation
        question: CÃ¢u há»i cá»§a user
        streaming: True Ä‘á»ƒ stream response
        use_reranker: True Ä‘á»ƒ dÃ¹ng reranker
        
    Returns:
        str náº¿u streaming=False
        Generator[str] náº¿u streaming=True
    """
    # Láº¥y conversation
    conversation = db.query(models.Conversation).filter(
        models.Conversation.id == conversation_id
    ).first()
    
    if not conversation:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found"
        )
    
    vector_meta = conversation.vector_store_meta
    
    # Kiá»ƒm tra vector store
    if not vector_meta:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Vector store metadata not found"
        )
    
    if vector_meta.status == "empty":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Vector store is empty. Please build it first."
        )
    
    if vector_meta.status == "building":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Vector store is being built. Please wait."
        )
    
    if vector_meta.status == "error":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Vector store build failed: {vector_meta.error_message}"
        )
    
    if vector_meta.status != "ready":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Vector store is not ready. Current status: {vector_meta.status}"
        )
    
    # Kiá»ƒm tra files tá»“n táº¡i
    if not os.path.exists(vector_meta.index_path):
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Vector store index file not found"
        )
    
    if not os.path.exists(vector_meta.meta_path):
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Vector store meta file not found"
        )
    
    try:
        # Táº¡o retriever
        retriever = create_retriever(
            index_path=vector_meta.index_path,
            meta_path=vector_meta.meta_path
        )
        
        # Gá»i RAG pipeline
        answer = answer_question_with_store(
            question=question,
            retriever=retriever,
            streaming=streaming,
            use_reranker=use_reranker,
            reranker_top_k=3,
            detect_language=True
        )
        
        return answer
        
    except Exception as e:
        print(f"âŒ Error answering question: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to answer question: {str(e)}"
        )


def get_vector_store_status(
    db: Session,
    conversation_id: int
) -> models.VectorStoreMeta:
    """
    Láº¥y tráº¡ng thÃ¡i vector store
    
    Args:
        db: Database session
        conversation_id: ID cá»§a conversation
        
    Returns:
        VectorStoreMeta instance
    """
    vector_meta = db.query(models.VectorStoreMeta).filter(
        models.VectorStoreMeta.conversation_id == conversation_id
    ).first()
    
    if not vector_meta:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Vector store not found"
        )
    
    return vector_meta


def rebuild_vector_store_for_conversation(
    db: Session,
    conversation_id: int
) -> None:
    """
    Rebuild vector store cho conversation (xÃ³a cÅ© vÃ  táº¡o má»›i)
    
    Args:
        db: Database session
        conversation_id: ID cá»§a conversation
    """
    print(f"\nğŸ”„ Rebuilding vector store for conversation {conversation_id}")
    
    # Láº¥y vector meta
    vector_meta = db.query(models.VectorStoreMeta).filter(
        models.VectorStoreMeta.conversation_id == conversation_id
    ).first()
    
    if not vector_meta:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Vector store not found"
        )
    
    # XÃ³a files cÅ© náº¿u cÃ³
    try:
        if os.path.exists(vector_meta.index_path):
            os.remove(vector_meta.index_path)
            print("  âœ… Deleted old index file")
        
        if os.path.exists(vector_meta.meta_path):
            os.remove(vector_meta.meta_path)
            print("  âœ… Deleted old meta file")
    except Exception as e:
        print(f"  âš ï¸  Error deleting old files: {e}")
    
    # Reset status
    vector_meta.status = "empty"
    vector_meta.doc_count = 0
    vector_meta.error_message = None
    db.commit()
    
    # Build láº¡i
    build_vector_store_for_conversation(db, conversation_id)


def validate_conversation_vector_store(
    db: Session,
    conversation_id: int
) -> dict:
    """
    Validate vector store cá»§a conversation
    
    Args:
        db: Database session
        conversation_id: ID cá»§a conversation
        
    Returns:
        Dict chá»©a thÃ´ng tin validation
    """
    vector_meta = get_vector_store_status(db, conversation_id)
    
    validation = {
        "conversation_id": conversation_id,
        "status": vector_meta.status,
        "doc_count": vector_meta.doc_count,
        "dimension": vector_meta.dimension,
        "files_exist": {
            "index": os.path.exists(vector_meta.index_path),
            "meta": os.path.exists(vector_meta.meta_path)
        },
        "is_ready": False,
        "errors": []
    }
    
    # Kiá»ƒm tra status
    if vector_meta.status != "ready":
        validation["errors"].append(f"Status is {vector_meta.status}, not ready")
    
    # Kiá»ƒm tra files
    if not validation["files_exist"]["index"]:
        validation["errors"].append("Index file not found")
    
    if not validation["files_exist"]["meta"]:
        validation["errors"].append("Meta file not found")
    
    # Kiá»ƒm tra doc count
    if vector_meta.doc_count == 0:
        validation["errors"].append("No documents indexed")
    
    # Tá»•ng káº¿t
    validation["is_ready"] = (
        vector_meta.status == "ready" and
        validation["files_exist"]["index"] and
        validation["files_exist"]["meta"] and
        vector_meta.doc_count > 0
    )
    
    return validation